{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:43<00:00,  1.51it/s]\n",
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2264\n",
      "2053\n",
      "MobileNetSmall3D14.pth test loss: 0.4099, ball test accuracy: 84.04% strike test accuracy: 76.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:39<00:00,  1.54it/s]\n",
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\n",
      "2206\n",
      "MobileNetSmall3D21.pth test loss: 0.4111, ball test accuracy: 74.46% strike test accuracy: 82.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:40<00:00,  1.53it/s]\n",
      "100%|██████████| 337/337 [03:39<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781\n",
      "2332\n",
      "MobileNetSmall3D28.pth test loss: 0.4448, ball test accuracy: 66.11% strike test accuracy: 86.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:41<00:00,  1.52it/s]\n",
      "100%|██████████| 337/337 [03:37<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2088\n",
      "2131\n",
      "MobileNetSmall3D17.pth test loss: 0.4184, ball test accuracy: 77.51% strike test accuracy: 79.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:39<00:00,  1.54it/s]\n",
      "100%|██████████| 337/337 [03:39<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "2165\n",
      "MobileNetSmall3D19.pth test loss: 0.4204, ball test accuracy: 76.02% strike test accuracy: 80.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:40<00:00,  1.53it/s]\n",
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1949\n",
      "2228\n",
      "MobileNetSmall3D27.pth test loss: 0.4117, ball test accuracy: 72.35% strike test accuracy: 82.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:39<00:00,  1.54it/s]\n",
      "100%|██████████| 337/337 [03:36<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2211\n",
      "2048\n",
      "MobileNetSmall3D6.pth test loss: 0.4186, ball test accuracy: 82.07% strike test accuracy: 76.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:39<00:00,  1.54it/s]\n",
      "100%|██████████| 337/337 [03:37<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168\n",
      "2099\n",
      "MobileNetSmall3D20.pth test loss: 0.4081, ball test accuracy: 80.48% strike test accuracy: 78.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:40<00:00,  1.53it/s]\n",
      "100%|██████████| 337/337 [03:39<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2376\n",
      "1966\n",
      "MobileNetSmall3D26.pth test loss: 0.3947, ball test accuracy: 88.20% strike test accuracy: 73.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:41<00:00,  1.52it/s]\n",
      "100%|██████████| 337/337 [03:40<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2276\n",
      "2026\n",
      "MobileNetSmall3D10.pth test loss: 0.4154, ball test accuracy: 84.48% strike test accuracy: 75.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:38<00:00,  1.55it/s]\n",
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988\n",
      "2194\n",
      "MobileNetSmall3D11.pth test loss: 0.4371, ball test accuracy: 73.79% strike test accuracy: 81.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n",
      "100%|██████████| 337/337 [03:39<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2359\n",
      "1967\n",
      "MobileNetSmall3D23.pth test loss: 0.3902, ball test accuracy: 87.56% strike test accuracy: 73.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n",
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2377\n",
      "1910\n",
      "MobileNetSmall3D7.pth test loss: 0.4167, ball test accuracy: 88.23% strike test accuracy: 71.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:40<00:00,  1.53it/s]\n",
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2208\n",
      "2085\n",
      "MobileNetSmall3D8.pth test loss: 0.4140, ball test accuracy: 81.96% strike test accuracy: 77.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:40<00:00,  1.53it/s]\n",
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2185\n",
      "2095\n",
      "MobileNetSmall3D12.pth test loss: 0.4217, ball test accuracy: 81.11% strike test accuracy: 77.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:40<00:00,  1.53it/s]\n",
      "100%|██████████| 337/337 [03:39<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2324\n",
      "2018\n",
      "MobileNetSmall3D24.pth test loss: 0.3994, ball test accuracy: 86.27% strike test accuracy: 75.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:39<00:00,  1.54it/s]\n",
      "100%|██████████| 337/337 [03:37<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2112\n",
      "2135\n",
      "MobileNetSmall3D18.pth test loss: 0.4118, ball test accuracy: 78.40% strike test accuracy: 79.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:39<00:00,  1.54it/s]\n",
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2224\n",
      "2071\n",
      "MobileNetSmall3D15.pth test loss: 0.4137, ball test accuracy: 82.55% strike test accuracy: 76.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:40<00:00,  1.53it/s]\n",
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999\n",
      "2180\n",
      "MobileNetSmall3D13.pth test loss: 0.4210, ball test accuracy: 74.20% strike test accuracy: 81.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:40<00:00,  1.53it/s]\n",
      "100%|██████████| 337/337 [03:39<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2177\n",
      "2126\n",
      "MobileNetSmall3D29.pth test loss: 0.4040, ball test accuracy: 80.81% strike test accuracy: 79.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n",
      "100%|██████████| 337/337 [03:37<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2284\n",
      "2019\n",
      "MobileNetSmall3D9.pth test loss: 0.4135, ball test accuracy: 84.78% strike test accuracy: 75.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n",
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2066\n",
      "2195\n",
      "MobileNetSmall3D_CrossEntropyLoss()_finished.pth test loss: 0.4106, ball test accuracy: 76.69% strike test accuracy: 81.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:38<00:00,  1.54it/s]\n",
      "100%|██████████| 337/337 [03:36<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2181\n",
      "2130\n",
      "MobileNetSmall3D30.pth test loss: 0.4018, ball test accuracy: 80.96% strike test accuracy: 79.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:39<00:00,  1.54it/s]\n",
      "100%|██████████| 337/337 [03:39<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2217\n",
      "2087\n",
      "MobileNetSmall3D25.pth test loss: 0.3963, ball test accuracy: 82.29% strike test accuracy: 77.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:40<00:00,  1.53it/s]\n",
      "100%|██████████| 337/337 [03:39<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2307\n",
      "1962\n",
      "MobileNetSmall3D4.pth test loss: 0.4197, ball test accuracy: 85.63% strike test accuracy: 72.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:39<00:00,  1.53it/s]\n",
      "100%|██████████| 337/337 [03:36<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2401\n",
      "1934\n",
      "MobileNetSmall3D16.pth test loss: 0.3943, ball test accuracy: 89.12% strike test accuracy: 71.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:40<00:00,  1.53it/s]\n",
      "100%|██████████| 337/337 [03:39<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2118\n",
      "2156\n",
      "MobileNetSmall3D22.pth test loss: 0.4095, ball test accuracy: 78.62% strike test accuracy: 80.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [03:39<00:00,  1.53it/s]\n",
      "100%|██████████| 337/337 [03:37<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2388\n",
      "1928\n",
      "MobileNetSmall3D5.pth test loss: 0.4127, ball test accuracy: 88.64% strike test accuracy: 71.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''For testing our network'''\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from psutil import cpu_count\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader import PicklebotDataset, custom_collate\n",
    "from mobilenet import MobileNetLarge2D, MobileNetSmall2D, MobileNetSmall3D,MobileNetLarge3D\n",
    "from movinet import MoViNetA2\n",
    "from helpers import calculate_accuracy, calculate_accuracy_bce\n",
    "import os\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "def forward_pass(loader,model):\n",
    "    model.eval()\n",
    "    test_losses = [] \n",
    "    test_samples = 0\n",
    "    test_correct = 0\n",
    "\n",
    "    #calculate the loss\n",
    "    for test_features,test_labels in tqdm(loader):\n",
    "        test_features = test_features.to(torch.bfloat16).to(device)\n",
    "        test_labels = (test_labels.long()).to(device) \n",
    "        test_outputs = model(test_features)\n",
    "        # test_labels = test_labels.unsqueeze(1)\n",
    "        test_loss = criterion(test_outputs,test_labels)\n",
    "        test_losses.append(test_loss.item())\n",
    "        \n",
    "        test_correct += calculate_accuracy(test_outputs,test_labels)\n",
    "        \n",
    "        test_samples += len(test_labels)\n",
    "        \n",
    "\n",
    "    return test_losses, test_correct, test_samples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    #evaluate the model\n",
    "    balls_losses, balls_correct, balls_samples = forward_pass(ball_loader,model)\n",
    "    strikes_losses,strikes_correct, strikes_samples = forward_pass(strike_loader,model)\n",
    "    test_losses = balls_losses + strikes_losses\n",
    "    avg_test_loss = np.mean(test_losses)\n",
    "    print(balls_correct)\n",
    "    print(strikes_correct)\n",
    "    balls_accuracy = balls_correct / balls_samples \n",
    "    strikes_accuracy = strikes_correct / strikes_samples \n",
    "    return avg_test_loss, balls_accuracy, strikes_accuracy \n",
    "\n",
    "def state_dict_converter(state_dict):\n",
    "    for key in list(state_dict.keys()):\n",
    "        if key.startswith(\"_orig_mod.\"):\n",
    "            new_key = key.replace(\"_orig_mod.\", \"\")\n",
    "            state_dict[new_key] = state_dict[key]\n",
    "            del state_dict[key]\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "std = (0.2104, 0.1986, 0.1829)\n",
    "mean = (0.3939, 0.3817, 0.3314)\n",
    "batch_size = 8\n",
    "#annotations paths\n",
    "strike_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/strike_test_labels.csv'\n",
    "ball_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/ball_test_labels.csv'\n",
    "\n",
    "#video paths\n",
    "test_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/test_all_together'\n",
    "\n",
    "#establish our normalization using transforms, \n",
    "#note that we are doing this in our dataloader as opposed to in the training loop like with dali\n",
    "transform = transforms.Normalize(mean,std)\n",
    "\n",
    "\n",
    "ball_dataset = PicklebotDataset(ball_annotations_file,test_video_paths,transform=transform,dtype=torch.bfloat16)\n",
    "strike_dataset = PicklebotDataset(strike_annotations_file,test_video_paths,transform=transform,dtype=torch.bfloat16)\n",
    "ball_loader = DataLoader(ball_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count()//2)\n",
    "strike_loader = DataLoader(strike_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count()//2)\n",
    "\n",
    "\n",
    "model = MobileNetSmall3D(num_classes=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "file_dir = \"/home/henry/Documents/PythonProjects/old_checkpoints/MobileNetSmallWeightedResumed\"\n",
    "file_list = os.listdir(file_dir)\n",
    "for file in file_list:\n",
    "    state_dict = torch.load(f'{file_dir}/{file}')\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(torch.bfloat16)\n",
    "    avg_test_loss,balls_accuracy,strikes_accuracy = estimate_loss()\n",
    "    print(f'{file} test loss: {avg_test_loss:.4f}, ball test accuracy: {balls_accuracy * 100:.2f}% strike test accuracy: {strikes_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobilenet import MobileNetLarge3D\n",
    "import torch\n",
    "import os\n",
    "from torch.cuda.amp import autocast\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "def state_dict_converter(state_dict):\n",
    "    for key in list(state_dict.keys()):\n",
    "        if key.startswith(\"_orig_mod.\"):\n",
    "            new_key = key.replace(\"_orig_mod.\", \"\")\n",
    "            state_dict[new_key] = state_dict[key]\n",
    "            del state_dict[key]\n",
    "    return state_dict\n",
    "\n",
    "def transform(video, mean, std):\n",
    "    return (video - mean) / std\n",
    "\n",
    "std = (0.2104, 0.1986, 0.1829)\n",
    "mean = (0.3939, 0.3817, 0.3314)\n",
    "# Convert the mean and std to tensors\n",
    "std = torch.tensor(std).view(1, 3, 1, 1, 1)\n",
    "mean = torch.tensor(mean).view(1, 3, 1, 1, 1)\n",
    "\n",
    "test_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/test/balls'\n",
    "state_dict = torch.load(f'/home/henry/Documents/PythonProjects/Picklebot/weights/MobileNetLarge.pth')\n",
    "model = MobileNetLarge3D()\n",
    "model.load_state_dict(state_dict_converter(state_dict))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "video_paths = os.listdir(test_video_paths)\n",
    "\n",
    "for video_path in video_paths:\n",
    "    video = test_video_paths + '/' + video_path\n",
    "    video = torchvision.io.read_video(video,pts_unit='sec')[0].permute(-1,0,1,2).unsqueeze(0)/255\n",
    "    video = transform(video,mean,std)\n",
    "    with autocast():\n",
    "        out = model(video)\n",
    "    out_prob = F.softmax(out,dim=1)\n",
    "    print(out_prob,video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters in movinet: 4660762\n",
      "number of parameters in mobilenet large: 4191584\n",
      "number of parameters in mobilenet small: 1672816\n"
     ]
    }
   ],
   "source": [
    "'''Calculate the number of parameters in each model, for comparison purposes. \n",
    "   Note that movinet is about 2.8x larger than mobilenet small, and mobilenet large is about 2.5x larger than mobilenet small.'''\n",
    "\n",
    "from movinet import MoViNetA2\n",
    "from mobilenet import MobileNetLarge3D\n",
    "movinet = MoViNetA2()\n",
    "mobilenet_large = MobileNetLarge3D()\n",
    "mobilenet_small = MobileNetSmall3D()\n",
    "\n",
    "movinet_params = sum(p.numel() for p in movinet.parameters())\n",
    "mobilenet_large_params = sum(p.numel() for p in mobilenet_large.parameters())\n",
    "mobilenet_small_params = sum(p.numel() for p in mobilenet_small.parameters())\n",
    "print(f\"number of parameters in movinet: {movinet_params}\")\n",
    "print(f\"number of parameters in mobilenet large: {mobilenet_large_params}\")\n",
    "print(f\"number of parameters in mobilenet small: {mobilenet_small_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load videos with torchvision.io: 5600.379940986633\n",
      "Time to load videos with ffmpegio: 6023.769095897675\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataloader import custom_collate\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_video\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from ffmpegio.video import read\n",
    "from torchvision import transforms\n",
    "\n",
    "class PicklebotDataset(Dataset):\n",
    "    def __init__(self, annotations_file, video_dir, transform=None,target_transform=None,dtype=torch.float32):\n",
    "        self.video_labels = pd.read_csv(annotations_file,engine='pyarrow',header=None)\n",
    "        self.video_dir = video_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_labels)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        video_path = os.path.join(self.video_dir, self.video_labels.iloc[idx,0])\n",
    "        video = ((read_video(video_path,output_format=\"TCHW\",pts_unit='sec')[0]).to(self.dtype))/255\n",
    "        label = self.video_labels.iloc[idx,1]\n",
    "        if self.transform:\n",
    "            video = self.transform(video)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return video, label\n",
    "\n",
    "class PicklebotDatasetFFMPEGIO(Dataset):\n",
    "    def __init__(self, annotations_file, video_dir, transform=None,target_transform=None,dtype=torch.float32):\n",
    "        self.video_labels = pd.read_csv(annotations_file,engine='pyarrow',header=None)\n",
    "        self.video_dir = video_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_labels)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        video_path = os.path.join(self.video_dir, self.video_labels.iloc[idx,0])\n",
    "        video = ((torch.tensor(read(video_path)[1])).to(self.dtype))/255\n",
    "        video = video.permute(0,3,1,2)\n",
    "        label = self.video_labels.iloc[idx,1]\n",
    "        if self.transform:\n",
    "            video = self.transform(video)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return video, label\n",
    "    \n",
    "std = (0.2104, 0.1986, 0.1829)\n",
    "mean = (0.3939, 0.3817, 0.3314)\n",
    "batch_size=8\n",
    "\n",
    "dtype = torch.bfloat16\n",
    "#annotations paths\n",
    "train_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/train_labels.csv'\n",
    "val_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/val_labels.csv'\n",
    "\n",
    "#video paths\n",
    "train_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/train_all_together'\n",
    "val_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/val_all_together'\n",
    "\n",
    "#establish our normalization using transforms, \n",
    "#note that we are doing this in our dataloader as opposed to in the training loop like with dali\n",
    "transform = transforms.Normalize(mean,std)\n",
    "\n",
    "#dataset     \n",
    "train_dataset = PicklebotDataset(train_annotations_file,train_video_paths,transform=transform,dtype=dtype)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=8)\n",
    "\n",
    "ffmpegio_dataset = PicklebotDatasetFFMPEGIO(train_annotations_file,train_video_paths,transform=transform,dtype=dtype)\n",
    "ffmpegio_loader = DataLoader(ffmpegio_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=8)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for i, (video, label) in enumerate(train_loader):\n",
    "    pass\n",
    "\n",
    "print(f\"Time to load videos with torchvision.io: {time.time() - start}\") #5625.347644805908 seconds\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i, (video, label) in enumerate(ffmpegio_loader):\n",
    "    pass\n",
    "\n",
    "print(f\"Time to load videos with ffmpegio: {time.time() - start}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
