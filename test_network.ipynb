{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For testing our network'''\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from psutil import cpu_count\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader import PicklebotDataset, custom_collate\n",
    "from mobilenet import MobileNetLarge2D, MobileNetSmall2D, MobileNetSmall3D,MobileNetLarge3D\n",
    "from movinet import MoViNetA2\n",
    "from helpers import calculate_accuracy, calculate_accuracy_bce\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "def forward_pass(loader,model):\n",
    "    model.eval()\n",
    "    test_losses = [] \n",
    "    test_samples = 0\n",
    "    test_correct = 0\n",
    "\n",
    "    #calculate the loss\n",
    "    for test_features,test_labels in tqdm(loader):\n",
    "        test_features = test_features.to(torch.bfloat16).to(device)\n",
    "        test_labels = (test_labels.long()).to(device) \n",
    "        test_outputs = model(test_features)\n",
    "        # test_labels = test_labels.unsqueeze(1)\n",
    "        test_loss = criterion(test_outputs,test_labels)\n",
    "        test_losses.append(test_loss.item())\n",
    "        \n",
    "        test_correct += calculate_accuracy(test_outputs,test_labels)\n",
    "        \n",
    "        test_samples += len(test_labels)\n",
    "        \n",
    "\n",
    "    return test_losses, test_correct, test_samples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    #evaluate the model\n",
    "    balls_losses, balls_correct, balls_samples = forward_pass(ball_loader,model)\n",
    "    strikes_losses,strikes_correct, strikes_samples = forward_pass(strike_loader,model)\n",
    "    test_losses = balls_losses + strikes_losses\n",
    "    avg_test_loss = np.mean(test_losses)\n",
    "    print(balls_correct)\n",
    "    print(strikes_correct)\n",
    "    balls_accuracy = balls_correct / balls_samples \n",
    "    strikes_accuracy = strikes_correct / strikes_samples \n",
    "    return avg_test_loss, balls_accuracy, strikes_accuracy \n",
    "\n",
    "def state_dict_converter(state_dict):\n",
    "    for key in list(state_dict.keys()):\n",
    "        if key.startswith(\"_orig_mod.\"):\n",
    "            new_key = key.replace(\"_orig_mod.\", \"\")\n",
    "            state_dict[new_key] = state_dict[key]\n",
    "            del state_dict[key]\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "std = (0.2104, 0.1986, 0.1829)\n",
    "mean = (0.3939, 0.3817, 0.3314)\n",
    "batch_size = 4 \n",
    "#annotations paths\n",
    "strike_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/strike_test_labels.csv'\n",
    "ball_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/ball_test_labels.csv'\n",
    "\n",
    "#video paths\n",
    "test_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/test_all_together'\n",
    "\n",
    "#establish our normalization using transforms, \n",
    "#note that we are doing this in our dataloader as opposed to in the training loop like with dali\n",
    "transform = transforms.Normalize(mean,std)\n",
    "\n",
    "\n",
    "ball_dataset = PicklebotDataset(ball_annotations_file,test_video_paths,transform=transform)\n",
    "strike_dataset = PicklebotDataset(strike_annotations_file,test_video_paths,transform=transform)\n",
    "ball_loader = DataLoader(ball_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "strike_loader = DataLoader(strike_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "\n",
    "\n",
    "model = MobileNetLarge3D(num_classes=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "state_dict_36 = torch.load(f'/home/henry/Documents/PythonProjects/Picklebot/models/MobileNetLarge3D36.pth')\n",
    "state_dict_48 = torch.load(f'/home/henry/Documents/PythonProjects/Picklebot/models/MobileNetLarge3D48.pth')\n",
    "\n",
    "\n",
    "model.load_state_dict(state_dict_36)\n",
    "model.to(torch.bfloat16)\n",
    "avg_test_loss,balls_accuracy,strikes_accuracy = estimate_loss()\n",
    "print(f'Mobilenet Large 36 test loss: {avg_test_loss:.4f}, ball test accuracy: {balls_accuracy * 100:.2f}% strike test accuracy: {strikes_accuracy * 100:.2f}%')\n",
    "model.load_state_dict(state_dict_48)\n",
    "model.to(torch.bfloat16)\n",
    "avg_test_loss,balls_accuracy,strikes_accuracy = estimate_loss()\n",
    "print(f'Mobilenet Large 48 test loss: {avg_test_loss:.4f}, ball test accuracy: {balls_accuracy * 100:.2f}% strike test accuracy: {strikes_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here, we test the ensemble of 48 and 36. \n",
    "from mobilenet import MobileNetLarge3D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from psutil import cpu_count\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "from dataloader import PicklebotDataset, custom_collate\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method('spawn',force=True)\n",
    "\n",
    "def calculate_accuracy(outputs,labels):\n",
    "    predicted_classes = torch.argmax(outputs,dim=1).to(labels.device)\n",
    "    num_correct = torch.sum(predicted_classes == labels).item()\n",
    "    return num_correct\n",
    "\n",
    "def state_dict_converter(state_dict):\n",
    "    for key in list(state_dict.keys()):\n",
    "        if key.startswith(\"_orig_mod.\"):\n",
    "            new_key = key.replace(\"_orig_mod.\", \"\")\n",
    "            state_dict[new_key] = state_dict[key]\n",
    "            del state_dict[key]\n",
    "    return state_dict\n",
    "\n",
    "std = (0.2104, 0.1986, 0.1829)\n",
    "mean = (0.3939, 0.3817, 0.3314)\n",
    "annotations_file = \"/home/henry/Documents/PythonProjects/picklebotdataset/test_labels.csv\"\n",
    "test_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/test_all_together'\n",
    "transform = transforms.Normalize(mean,std)\n",
    "dataset = PicklebotDataset(annotations_file,test_video_paths,transform=transform)\n",
    "loader = DataLoader(dataset,batch_size=4,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "state_dict_36 = torch.load(f'/home/henry/Documents/PythonProjects/old_checkpoints/MobileNetLargeWeighted/MobileNetLarge3D36.pth')\n",
    "state_dict_48 = torch.load(f'/home/henry/Documents/PythonProjects/old_checkpoints/MobileNetLargeWeighted/MobileNetLarge3D48.pth')\n",
    "model_36 = MobileNetLarge3D()\n",
    "model_36.load_state_dict(state_dict_converter(state_dict_36))\n",
    "model_48 = MobileNetLarge3D()\n",
    "model_48.load_state_dict(state_dict_converter(state_dict_48))\n",
    "\n",
    "model_36.to(device)\n",
    "model_48.to(device)\n",
    "model_36.eval()\n",
    "model_48.eval()\n",
    "test_losses = 0\n",
    "test_samples = 0\n",
    "test_correct = 0\n",
    "\n",
    "#forward pass\n",
    "for videos, test_labels in tqdm(loader):\n",
    "    videos = videos.to(device)\n",
    "    test_labels = (test_labels.long()).to(device)\n",
    "    with autocast():\n",
    "        out_36 = model_36(videos)\n",
    "        out_48 = model_48(videos)\n",
    "    avg_out = (F.softmax(out_48,dim=1)+F.softmax(out_36,dim=1))/2\n",
    "    test_loss = criterion(avg_out,test_labels)\n",
    "    test_losses += test_loss.item()\n",
    "    test_correct += calculate_accuracy(avg_out,test_labels)\n",
    "    test_samples += len(test_labels)\n",
    "\n",
    "avg_accuracy = test_correct/test_samples\n",
    "avg_loss = test_losses/test_samples\n",
    "\n",
    "\n",
    "print(f\"As an ensemble, average accuracy: {avg_accuracy}, avg_loss: {avg_loss}\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters in movinet: 4660762\n",
      "number of parameters in mobilenet large: 4191584\n",
      "number of parameters in mobilenet small: 1672816\n"
     ]
    }
   ],
   "source": [
    "'''Calculate the number of parameters in each model, for comparison purposes. \n",
    "   Note that movinet is about 2.8x larger than mobilenet small, and mobilenet large is about 2.5x larger than mobilenet small.'''\n",
    "\n",
    "from movinet import MoViNetA2\n",
    "from mobilenet import MobileNetLarge3D\n",
    "movinet = MoViNetA2()\n",
    "mobilenet_large = MobileNetLarge3D()\n",
    "mobilenet_small = MobileNetSmall3D()\n",
    "\n",
    "n\n",
    "movinet_params = sum(p.numel() for p in movinet.parameters())\n",
    "mobilenet_large_params = sum(p.numel() for p in mobilenet_large.parameters())\n",
    "mobilenet_small_params = sum(p.numel() for p in mobilenet_small.parameters())\n",
    "print(f\"number of parameters in movinet: {movinet_params}\")\n",
    "print(f\"number of parameters in mobilenet large: {mobilenet_large_params}\")\n",
    "print(f\"number of parameters in mobilenet small: {mobilenet_small_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
