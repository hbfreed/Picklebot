{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For testing our network'''\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from psutil import cpu_count\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader import PicklebotDataset, custom_collate\n",
    "from mobilenet import MobileNetLarge2D, MobileNetSmall2D, MobileNetSmall3D,MobileNetLarge3D\n",
    "from movinet import MoViNetA2\n",
    "from helpers import calculate_accuracy, calculate_accuracy_bce\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "def forward_pass(loader,model):\n",
    "    model.eval()\n",
    "    test_losses = [] \n",
    "    test_samples = 0\n",
    "    test_correct = 0\n",
    "\n",
    "    #calculate the loss\n",
    "    for test_features,test_labels in tqdm(loader):\n",
    "        test_features = test_features.to(torch.bfloat16).to(device)\n",
    "        test_labels = (test_labels.long()).to(device) \n",
    "        test_outputs = model(test_features)\n",
    "        # test_labels = test_labels.unsqueeze(1)\n",
    "        test_loss = criterion(test_outputs,test_labels)\n",
    "        test_losses.append(test_loss.item())\n",
    "        \n",
    "        test_correct += calculate_accuracy(test_outputs,test_labels)\n",
    "        \n",
    "        test_samples += len(test_labels)\n",
    "        \n",
    "\n",
    "    return test_losses, test_correct, test_samples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    #evaluate the model\n",
    "    balls_losses, balls_correct, balls_samples = forward_pass(ball_loader,model)\n",
    "    strikes_losses,strikes_correct, strikes_samples = forward_pass(strike_loader,model)\n",
    "    test_losses = balls_losses + strikes_losses\n",
    "    avg_test_loss = np.mean(test_losses)\n",
    "    print(balls_correct)\n",
    "    print(strikes_correct)\n",
    "    balls_accuracy = balls_correct / balls_samples \n",
    "    strikes_accuracy = strikes_correct / strikes_samples \n",
    "    return avg_test_loss, balls_accuracy, strikes_accuracy \n",
    "\n",
    "def state_dict_converter(state_dict):\n",
    "    for key in list(state_dict.keys()):\n",
    "        if key.startswith(\"_orig_mod.\"):\n",
    "            new_key = key.replace(\"_orig_mod.\", \"\")\n",
    "            state_dict[new_key] = state_dict[key]\n",
    "            del state_dict[key]\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "std = (0.2104, 0.1986, 0.1829)\n",
    "mean = (0.3939, 0.3817, 0.3314)\n",
    "batch_size = 4 \n",
    "#annotations paths\n",
    "strike_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/strike_test_labels.csv'\n",
    "ball_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/ball_test_labels.csv'\n",
    "\n",
    "#video paths\n",
    "test_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/test_all_together'\n",
    "\n",
    "#establish our normalization using transforms, \n",
    "#note that we are doing this in our dataloader as opposed to in the training loop like with dali\n",
    "transform = transforms.Normalize(mean,std)\n",
    "\n",
    "\n",
    "ball_dataset = PicklebotDataset(ball_annotations_file,test_video_paths,transform=transform)\n",
    "strike_dataset = PicklebotDataset(strike_annotations_file,test_video_paths,transform=transform)\n",
    "ball_loader = DataLoader(ball_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "strike_loader = DataLoader(strike_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "\n",
    "\n",
    "model = MobileNetLarge3D(num_classes=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "state_dict_36 = torch.load(f'/home/henry/Documents/PythonProjects/Picklebot/models/MobileNetLarge3D36.pth')\n",
    "state_dict_48 = torch.load(f'/home/henry/Documents/PythonProjects/Picklebot/models/MobileNetLarge3D48.pth')\n",
    "\n",
    "\n",
    "model.load_state_dict(state_dict_36)\n",
    "model.to(torch.bfloat16)\n",
    "avg_test_loss,balls_accuracy,strikes_accuracy = estimate_loss()\n",
    "print(f'Mobilenet Large 36 test loss: {avg_test_loss:.4f}, ball test accuracy: {balls_accuracy * 100:.2f}% strike test accuracy: {strikes_accuracy * 100:.2f}%')\n",
    "model.load_state_dict(state_dict_48)\n",
    "model.to(torch.bfloat16)\n",
    "avg_test_loss,balls_accuracy,strikes_accuracy = estimate_loss()\n",
    "print(f'Mobilenet Large 48 test loss: {avg_test_loss:.4f}, ball test accuracy: {balls_accuracy * 100:.2f}% strike test accuracy: {strikes_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here, we test the ensemble of 48 and 36. \n",
    "from mobilenet import MobileNetLarge3D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from psutil import cpu_count\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "from dataloader import PicklebotDataset, custom_collate\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def calculate_accuracy(outputs,labels):\n",
    "    predicted_classes = torch.argmax(outputs,dim=1).to(labels.device)\n",
    "    num_correct = torch.sum(predicted_classes == labels).item()\n",
    "    return num_correct\n",
    "\n",
    "def state_dict_converter(state_dict):\n",
    "    for key in list(state_dict.keys()):\n",
    "        if key.startswith(\"_orig_mod.\"):\n",
    "            new_key = key.replace(\"_orig_mod.\", \"\")\n",
    "            state_dict[new_key] = state_dict[key]\n",
    "            del state_dict[key]\n",
    "    return state_dict\n",
    "\n",
    "std = (0.2104, 0.1986, 0.1829)\n",
    "mean = (0.3939, 0.3817, 0.3314)\n",
    "annotations_file = \"/home/henry/Documents/PythonProjects/picklebotdataset/test_labels.csv\"\n",
    "test_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/test_all_together'\n",
    "transform = transforms.Normalize(mean,std)\n",
    "dataset = PicklebotDataset(annotations_file,test_video_paths,transform=transform)\n",
    "loader = DataLoader(dataset,batch_size=4,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "state_dict_36 = torch.load(f'/home/henry/Documents/PythonProjects/old_checkpoints/MobileNetLargeWeighted/MobileNetLarge3D36.pth')\n",
    "state_dict_48 = torch.load(f'/home/henry/Documents/PythonProjects/old_checkpoints/MobileNetLargeWeighted/MobileNetLarge3D48.pth')\n",
    "model_36 = MobileNetLarge3D()\n",
    "model_36.load_state_dict(state_dict_converter(state_dict_36))\n",
    "model_48 = MobileNetLarge3D()\n",
    "model_48.load_state_dict(state_dict_converter(state_dict_48))\n",
    "\n",
    "model_36.to(device)\n",
    "model_48.to(device)\n",
    "model_36.eval()\n",
    "model_48.eval()\n",
    "test_losses = 0\n",
    "test_samples = 0\n",
    "test_correct = 0\n",
    "\n",
    "#forward pass\n",
    "for videos, test_labels in tqdm(loader):\n",
    "    videos = videos.to(device)\n",
    "    test_labels = (test_labels.long()).to(device)\n",
    "    with autocast():\n",
    "        out_36 = model_36(videos)\n",
    "        out_48 = model_48(videos)\n",
    "    avg_out = (F.softmax(out_48,dim=1)+F.softmax(out_36,dim=1))/2\n",
    "    test_loss = criterion(avg_out,test_labels)\n",
    "    test_losses += test_loss.item()\n",
    "    test_correct += calculate_accuracy(avg_out,test_labels)\n",
    "    test_samples += len(test_labels)\n",
    "\n",
    "avg_accuracy = test_correct/test_samples\n",
    "avg_loss = test_losses/test_samples\n",
    "\n",
    "\n",
    "print(f\"As an ensemble, average accuracy: {avg_accuracy}, avg_loss: {avg_loss}\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try visualizing the first layer of filters\n",
    "from mobilenet import MobileNetLarge3D\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from IPython.display import Image, display\n",
    "from matplotlib.animation import FuncAnimation\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "def state_dict_converter(state_dict):\n",
    "    for key in list(state_dict.keys()):\n",
    "        if key.startswith(\"_orig_mod.\"):\n",
    "            new_key = key.replace(\"_orig_mod.\", \"\")\n",
    "            state_dict[new_key] = state_dict[key]\n",
    "            del state_dict[key]\n",
    "    return state_dict\n",
    "\n",
    "state_dict_36 = torch.load(f'/home/henry/Documents/PythonProjects/Picklebot/weights/MobileNetLarge.pth')\n",
    "model = MobileNetLarge3D()\n",
    "model.eval()\n",
    "model.load_state_dict(state_dict_converter(state_dict_36))\n",
    "weights = model.block1[0].weight.clone().detach()\n",
    "for i in range(weights.shape[0]):\n",
    "    arr = weights[i].cpu().numpy()\n",
    "    fig,ax = plt.subplots()\n",
    "    im = ax.imshow(arr[0])\n",
    "    def update_frame(num):\n",
    "        im.set_array(arr[num]%arr.shape[-1])\n",
    "        return [im]\n",
    "    ani = FuncAnimation(fig, update_frame, frames=range(arr.shape[-1]))\n",
    "    writergif = imageio.get_writer(f'/home/henry/Documents/PythonProjects/first_layer_filters/first_layer_filter_{i}.gif', mode='I', duration=0.1)\n",
    "    ani.save(f'/home/henry/Documents/PythonProjects/first_layer_filters/first_layer_filter_{i}.gif', writer=writergif)\n",
    "    writergif.close()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters in movinet: 4660762\n",
      "number of parameters in mobilenet large: 4191584\n",
      "number of parameters in mobilenet small: 1672816\n"
     ]
    }
   ],
   "source": [
    "'''Calculate the number of parameters in each model, for comparison purposes. \n",
    "   Note that movinet is about 2.8x larger than mobilenet small, and mobilenet large is about 2.5x larger than mobilenet small.'''\n",
    "\n",
    "from movinet import MoViNetA2\n",
    "from mobilenet import MobileNetLarge3D\n",
    "movinet = MoViNetA2()\n",
    "mobilenet_large = MobileNetLarge3D()\n",
    "mobilenet_small = MobileNetSmall3D()\n",
    "\n",
    "movinet_params = sum(p.numel() for p in movinet.parameters())\n",
    "mobilenet_large_params = sum(p.numel() for p in mobilenet_large.parameters())\n",
    "mobilenet_small_params = sum(p.numel() for p in mobilenet_small.parameters())\n",
    "print(f\"number of parameters in movinet: {movinet_params}\")\n",
    "print(f\"number of parameters in mobilenet large: {mobilenet_large_params}\")\n",
    "print(f\"number of parameters in mobilenet small: {mobilenet_small_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4305, 0.5695]], grad_fn=<SoftmaxBackward0>) ball_inside.mp4\n"
     ]
    }
   ],
   "source": [
    "#here, we test the ensemble of 48 and 36. \n",
    "from mobilenet import MobileNetLarge3D\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from psutil import cpu_count\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "from dataloader import PicklebotDataset, custom_collate\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "\n",
    "def state_dict_converter(state_dict):\n",
    "    for key in list(state_dict.keys()):\n",
    "        if key.startswith(\"_orig_mod.\"):\n",
    "            new_key = key.replace(\"_orig_mod.\", \"\")\n",
    "            state_dict[new_key] = state_dict[key]\n",
    "            del state_dict[key]\n",
    "    return state_dict\n",
    "\n",
    "def transform(video, mean, std):\n",
    "    return (video - mean) / std\n",
    "\n",
    "std = (0.2104, 0.1986, 0.1829)\n",
    "mean = (0.3939, 0.3817, 0.3314)\n",
    "# Convert the mean and std to tensors\n",
    "std = torch.tensor(std).view(1, 3, 1, 1, 1)\n",
    "mean = torch.tensor(mean).view(1, 3, 1, 1, 1)\n",
    "\n",
    "test_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/test/balls'\n",
    "state_dict = torch.load(f'/home/henry/Documents/PythonProjects/Picklebot/weights/MobileNetLarge.pth')\n",
    "model = MobileNetLarge3D()\n",
    "model.load_state_dict(state_dict_converter(state_dict))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "video_paths = os.listdir(test_video_paths)\n",
    "\n",
    "video_paths = ['ball_inside.mp4']\n",
    "test_video_paths = '/home/henry/Documents/PythonProjects/Picklebot/demo_files'\n",
    "for video_path in video_paths:\n",
    "    video = test_video_paths + '/' + video_path\n",
    "    video = torchvision.io.read_video(video,pts_unit='sec')[0].permute(-1,0,1,2).unsqueeze(0)/255\n",
    "    video = transform(video,mean,std)\n",
    "    with autocast():\n",
    "        out = model(video)\n",
    "    out_prob = F.softmax(out,dim=1)\n",
    "    print(out_prob,video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run this cell (press the 'play' button) to run Picklebot for your choice of video. It may take a second to load everything, but inference is fast, even on the cpu.\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import HTML\n",
    "from mobilenet import MobileNetLarge3D\n",
    "from torchvision.io import read_video\n",
    "import mediapy\n",
    "import time\n",
    "\n",
    "std = (0.2104, 0.1986, 0.1829)\n",
    "mean = (0.3939, 0.3817, 0.3314)\n",
    "\n",
    "# Convert the mean and std to tensors\n",
    "mean = torch.tensor(mean).view(1, 3, 1, 1, 1)\n",
    "std = torch.tensor(std).view(1, 3, 1, 1, 1)\n",
    "\n",
    "def classify_pitch(confidence_scores):\n",
    "    if torch.argmax(confidence_scores) == 0:\n",
    "        call = 'Ball'\n",
    "    elif torch.argmax(confidence_scores) == 1:\n",
    "        call = 'Strike'\n",
    "    else:\n",
    "        print(\"that's odd, something is wrong\")\n",
    "        pass\n",
    "    return call\n",
    "\n",
    "def call_pitch(pitch):\n",
    "    pitch = 'demo_files/' + pitch\n",
    "    video = mediapy.read_video(pitch)\n",
    "    mediapy.show_video(video,width=600)\n",
    "\n",
    "    pitch_tensor = (read_video(pitch,pts_unit='sec')[0].permute(-1,0,1,2)).unsqueeze(0)/255\n",
    "    pitch_tensor = (pitch_tensor-mean)/std #normalize the pitch tensor\n",
    "    # load the model, load the model's weights\n",
    "    model = MobileNetLarge3D()\n",
    "    model.load_state_dict(torch.load('weights/MobileNetLarge.pth',map_location=torch.device('cpu')))\n",
    "\n",
    "    # run the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(pitch_tensor)\n",
    "    output = F.softmax(output,dim=1)\n",
    "    final_call = classify_pitch(output)\n",
    "\n",
    "    return final_call\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ball_videos = ['ball_high.mp4','ball_outside.mp4','ball_in_dirt.mp4']\n",
    "strike_videos = ['strike_middle.mp4','strike_outside_corner.mp4','strike_high.mp4']\n",
    "\n",
    "pitch_choice = 'Strike Down the Middle' #@param ['Ball High', 'Ball Outside', 'Ball in Dirt', 'Strike Down the Middle', 'Strike Outside Corner', 'Strike High']\n",
    "\n",
    "choice_map = {\n",
    "    'Ball High':ball_videos[0],\n",
    "    'Ball Outside':ball_videos[1],\n",
    "    'Ball in Dirt':ball_videos[2],\n",
    "    'Strike Down the Middle':strike_videos[0], \n",
    "    'Strike Low and Outside':strike_videos[1], \n",
    "    'Strike High':strike_videos[2] \n",
    "}\n",
    "pitch = choice_map[pitch_choice]\n",
    "\n",
    "final_call = call_pitch(pitch)\n",
    "\n",
    "time.sleep(1) #wait for the video to play for ux purposes, then display the final call. These mobilenets are fast!\n",
    "HTML(f\"<h1>{final_call}!<h1>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
