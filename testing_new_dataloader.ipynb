{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2 loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 811/811 [05:54<00:00,  2.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 354.9956748485565\n",
      "old loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/811 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "from torchvision.io import read_video\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader import custom_collate\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "dtype = torch.bfloat16\n",
    "val_annotations_file = '/home/henry/Documents/PythonProjects/picklebot_2m/picklebot_130k_val.csv'\n",
    "video_paths = '/home/henry/Documents/PythonProjects/picklebot_2m/picklebot_130k_all_together'\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "class cv2PicklebotDataset(Dataset):\n",
    "    def __init__(self, annotations_file, video_dir, transform=None, target_transform=None, dtype=torch.bfloat16):\n",
    "        self.video_labels = pd.read_csv(annotations_file, engine='pyarrow', encoding='ISO-8859-1')\n",
    "        self.video_dir = video_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.video_labels.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        video_path = os.path.join(self.video_dir, self.video_labels['filename'][idx])\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = torch.from_numpy(frame).permute(2, 0, 1).to(self.dtype) / 255\n",
    "            frames.append(frame)\n",
    "        cap.release()\n",
    "        video = torch.stack(frames)\n",
    "        label = self.video_labels[\"zone\"][idx]\n",
    "        if self.transform:\n",
    "            video = self.transform(video)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return video, label\n",
    "    \n",
    "class PicklebotDataset(Dataset):\n",
    "    def __init__(self, annotations_file, video_dir, transform=None,target_transform=None,dtype=torch.bfloat16):\n",
    "        self.video_labels = pd.read_csv(annotations_file,engine='pyarrow',encoding='ISO-8859-1')\n",
    "        self.video_dir = video_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.video_labels.shape[0]\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        video_path = os.path.join(self.video_dir, self.video_labels['filename'][idx])\n",
    "        video = ((read_video(video_path,output_format=\"TCHW\",pts_unit='sec')[0]).to(self.dtype))/255\n",
    "        label = self.video_labels[\"zone\"][idx]\n",
    "        if self.transform:\n",
    "            video = self.transform(video)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return video, label\n",
    "    \n",
    "\n",
    "\n",
    "cv2val_dataset = cv2PicklebotDataset(val_annotations_file,video_paths,dtype=dtype)\n",
    "val_dataset = PicklebotDataset(val_annotations_file,video_paths,dtype=dtype)\n",
    "cv2val_loader = DataLoader(cv2val_dataset, batch_size=batch_size,shuffle=False,collate_fn=custom_collate,num_workers=16,pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False,collate_fn=custom_collate,num_workers=16,pin_memory=True)\n",
    "\n",
    "\n",
    "#test how long it takes each loader to load the data, passing in the loop, and running both loaders twice\n",
    "for i in range(2):\n",
    "    print('cv2 loader')\n",
    "    start = time.time()\n",
    "    for batch in tqdm(cv2val_loader):\n",
    "        pass\n",
    "        batch = None\n",
    "    print('time:',time.time()-start)\n",
    "    \n",
    "    gc.collect()\n",
    "    print('old loader')\n",
    "    start = time.time()\n",
    "    for batch in tqdm(val_loader):\n",
    "        pass\n",
    "        batch = None\n",
    "    \n",
    "    print('time:',time.time()-start)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader import custom_collate, PicklebotDataset\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "annotations_file = '/home/henry/Documents/PythonProjects/picklebot_2m/picklebot_130k_train.csv'\n",
    "video_paths = '/home/henry/Documents/PythonProjects/picklebot_2m/picklebot_130k_all_together'\n",
    "batch_size = 16\n",
    "\n",
    "for be in ['opencv']: #,'torchvision']:\n",
    "    #start the timer\n",
    "    start = time.time()    \n",
    "    dataset = PicklebotDataset(annotations_file,video_paths,dtype=dtype,backend=be)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size,shuffle=False,collate_fn=custom_collate,num_workers=6,pin_memory=True)\n",
    "\n",
    "\n",
    "    for i in tqdm(loader):\n",
    "        pass\n",
    "    print(f'time for {be}:',time.time()-start)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all batch_size=16\n",
    "#num_workers = 4\n",
    "# 100%|██████████| 6483/6483 [1:02:53<00:00,  1.72it/s]time for opencv: 3773.560480117798\n",
    "\n",
    "#num_workers = 6\n",
    "\n",
    "\n",
    "\n",
    "# num_workers = 8,\n",
    "\n",
    "# 100%|██████████| 6483/6483 [45:50<00:00,  2.36it/s]  \n",
    "# time for torchvision: 2751.082986831665\n",
    "# 100%|██████████| 6483/6483 [39:01<00:00,  2.77it/s] \n",
    "# time for opencv: 2341.418078660965\n",
    "\n",
    "# num_workers = 12 (yes, opencv is practically the same!)\n",
    "# 100%|██████████| 6483/6483 [39:31<00:00,  2.73it/s] \n",
    "# time for torchvision: 2372.112513780594\n",
    "# 100%|██████████| 6483/6483 [39:01<00:00,  2.77it/s] \n",
    "# time for opencv: 2341.3904235363007\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
