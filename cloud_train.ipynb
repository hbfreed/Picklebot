{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''using torchvision for dataloading'''\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "from psutil import cpu_count\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader import PicklebotDataset, custom_collate\n",
    "from mobilenet import MobileNetLarge2D, MobileNetSmall2D, MobileNetSmall3D,MobileNetLarge3D\n",
    "from helpers import calculate_accuracy, initialize_mobilenet_weights\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "'''strikes are 1, ballss are 2 since we pad with 0s and cross entropy loss has to ignore something.'''\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#hyperparameters\n",
    "learning_rate = 3e-4 #the paper quotes rmsprop with 0.1 lr, but we have a tiny batch size, and are using AdamW\n",
    "batch_size = 4 #the paper quotes 128 images/chip, but with video we have to change this\n",
    "max_iters = 2000\n",
    "eval_interval = 50\n",
    "weight_decay = 0.0005\n",
    "momentum = 0.9\n",
    "eps = np.sqrt(0.002) #From the pytorch blog post, \"a reasonable approximation can be taken with the formula PyTorch_eps = sqrt(TF_eps).\"\n",
    "use_autocast = False\n",
    "\n",
    "#video paths\n",
    "train_video_paths = '/workspace/picklebotdataset/train'\n",
    "val_video_paths = '/workspace/picklebotdataset/val'\n",
    "\n",
    "#annotations paths\n",
    "train_annotations_file = '/home/hankhome/Documents/PythonProjects/picklebotdataset/train_labels.csv'\n",
    "val_annotations_file = '/home/hankhome/Documents/PythonProjects/picklebotdataset/val_labels.csv'\n",
    "\n",
    "#video paths\n",
    "train_video_paths = '/home/hankhome/Documents/PythonProjects/picklebotdataset/train_all_together'\n",
    "val_video_paths = '/home/hankhome/Documents/PythonProjects/picklebotdataset/val_all_together'\n",
    "\n",
    "#establish our normalization using transforms\n",
    "transform = transforms.Normalize((0.5,), (0.5,))\n",
    "\n",
    "#dataset     \n",
    "train_dataset = PicklebotDataset(train_annotations_file,train_video_paths,transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "val_dataset = PicklebotDataset(val_annotations_file,val_video_paths,transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "\n",
    "#model, optimizer, loss function\n",
    "model = MobileNetSmall3D().to(device)\n",
    "\n",
    "#initialize weights\n",
    "initialize_mobilenet_weights(model)\n",
    "\n",
    "#for multi-gpu\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# optimizer = optim.RMSprop(params=model.parameters(),lr=learning_rate,weight_decay=weight_decay,momentum=momentum,eps=eps) #starting with AdamW for now. \n",
    "optimizer = optim.AdamW(params=model.parameters(),lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "scaler = GradScaler()\n",
    "model_name = 'mobilenetsmall_3D_lambda' \n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    #evaluate the model\n",
    "    model.eval()\n",
    "    val_losses = [] \n",
    "    correct_predictions = 0\n",
    "\n",
    "    #calculate the loss\n",
    "    for val_features,val_labels in val_loader:\n",
    "        val_features = val_features.to(device)\n",
    "        val_labels = val_labels.to(torch.int64) #waiting to move to device until after forward pass, idk if this matters\n",
    "        val_labels = val_labels.expand(val_features.shape[2]) #this is only for our lstm T -> batch size, a lame hack\n",
    "        \n",
    "        val_outputs = model(val_features)\n",
    "        \n",
    "        val_loss = criterion(val_outputs,val_labels.to(device))\n",
    "        \n",
    "        val_losses.append(val_loss.item())\n",
    "         \n",
    "        correct_predictions += calculate_accuracy(val_outputs,val_labels)\n",
    "    \n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    val_accuracy = correct_predictions / len(val_loader.dataset)\n",
    "    return avg_val_loss, val_accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#try except block so we can manually early stop while saving the model\n",
    "#training loop\n",
    "start_time = time.time()\n",
    "train_losses = []\n",
    "train_percent = []\n",
    "val_losses = []\n",
    "val_percent = []\n",
    "\n",
    "\n",
    "#plot losses\n",
    "plt.ion()\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12,4))\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Val Loss')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "#plot accuracy\n",
    "ax2.plot(train_percent, label='Train Accuracy')\n",
    "ax2.plot(val_percent, label='Val Accuracy')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "\n",
    "try:\n",
    "    for iter in range(max_iters):\n",
    "        \n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_samples = 0\n",
    "        #forward pass\n",
    "        for batch_idx, (features,labels) in tqdm(enumerate(train_loader)):\n",
    "            \n",
    "            labels = labels.to(torch.int64)\n",
    "            features = features.to(device)\n",
    "            labels = labels.expand(features.shape[2]) #this is only for our lstm T -> batch size, a lame hack\n",
    "            \n",
    "            #zero the gradients\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if use_autocast:    \n",
    "                with autocast():\n",
    "                    outputs = model(features)\n",
    "                    loss = criterion(outputs,labels.to(device))\n",
    "                \n",
    "                #backprop & update weights\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            else:\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs,labels.to(device))\n",
    "\n",
    "                #backprop & update weights\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "\n",
    "            batch_correct = calculate_accuracy(outputs,labels)\n",
    "            train_correct += batch_correct\n",
    "            train_samples += len(labels)\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "            \n",
    "            #evaluate the model\n",
    "            avg_train_loss = np.mean(train_losses)\n",
    "            train_percent.append(train_correct / train_samples)\n",
    "            val_loss, val_accuracy = estimate_loss()\n",
    "        \n",
    "            val_losses.append(val_loss) #loss of the val batch\n",
    "            val_percent.append(val_accuracy) #percent of correct predictions in the val batch\n",
    "\n",
    "            print(f\"step {iter}: train loss:  {avg_train_loss:.4f}, val loss: {val_loss:.4f}\")\n",
    "            print(f\"step {iter}: train accuracy:  {train_percent[-1]*100:.2f}%, val accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "\n",
    "            # #plot the losses\n",
    "            ax1.plot(train_losses, label='Train Loss')\n",
    "            ax1.plot(val_losses, label='Val Loss')\n",
    "\n",
    "            #plot the accuracy\n",
    "            ax2.plot(train_percent, label='Train Accuracy')\n",
    "            ax2.plot(val_percent, label='Val Accuracy')\n",
    "\n",
    "\n",
    "            fig.canvas.draw()\n",
    "            fig.canvas.flush_events()\n",
    "            plt.pause(0.001)\n",
    "\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        remaining_iters = max_iters - iter\n",
    "        avg_time_per_iter = elapsed / (iter + 1)\n",
    "        estimated_remaining_time = remaining_iters * avg_time_per_iter\n",
    "\n",
    "        tqdm.write(f\"Iter [{iter+1}/{max_iters}] - Elapsed Time: {elapsed:.2f}s  Remaining Time: [{estimated_remaining_time:.2f}]\")\n",
    "        if iter == max_iters -1:\n",
    "            print(\"Training completed:\") \n",
    "            print(f\"Final train loss: {train_losses[-1]:.4f},\")\n",
    "            print(f\"Final val loss: {val_losses[-1]:.4f}, \")\n",
    "            print(f\"Final train accuracy: {train_percent[-1]*100:.2f}%, \")\n",
    "            print(f\"Final val accuracy: {val_percent[-1]*100:.2f}%\") \n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"Keyboard interrupt,\\nFinal train loss: {train_losses[-1]:.4f}, \")\n",
    "    print(f\"Final val loss: {val_losses[-1]:.4f}, \")\n",
    "    print(f\"Final train accuracy: {train_percent[-1]*100:.2f}%, \")\n",
    "    print(f\"Final val accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "\n",
    "finally:\n",
    "    torch.save(model.state_dict(), f'{model_name}.pth')\n",
    "    with open(f'{model_name}_train_losses.npy', 'wb') as f:\n",
    "        np.save(f, np.array(train_losses))\n",
    "    with open(f'{model_name}_val_losses.npy', 'wb') as f:\n",
    "        np.save(f, np.array(val_losses))\n",
    "    with open(f'{model_name}_train_percent.npy', 'wb') as f:\n",
    "        np.save(f, np.array(train_percent))\n",
    "    with open(f'{model_name}_val_percent.npy', 'wb') as f:\n",
    "        np.save(f, np.array(val_percent))\n",
    "    print(f\"Model saved!\") \n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This version of the program uses Nvidia Dali to load data, not torchvision.io.read_video,\n",
    "   It should be substantially faster, especially with multiple gpus, perhaps a good setup \n",
    "   would be one to load the videos, one to run the training loop? Perhaps not as I learned more about it.\n",
    "\n",
    "    Eventually, this and the other version in this notebook should be merged into one notebook, with a flag to choose which to use.\n",
    "   \n",
    "'''\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import nvidia.dali.fn as fn\n",
    "from nvidia.dali.plugin.pytorch import DALIClassificationIterator, LastBatchPolicy\n",
    "from nvidia.dali.backend import TensorListGPU\n",
    "from nvidia.dali import pipeline_def\n",
    "from tqdm import tqdm\n",
    "from psutil import cpu_count\n",
    "from mobilenet import MobileNetLarge2D, MobileNetSmall2D, MobileNetSmall3D,MobileNetLarge3D\n",
    "from helpers import calculate_accuracy, initialize_mobilenet_weights, video_pipeline\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "'''\n",
    "Our mean is ([0.3939, 0.3817, 0.3314])\n",
    "Our std is ([0.2104, 0.1986, 0.1829])\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''Strikes are 0, balls 1 we will eventually pad with 2 or something so cross entropy loss can ignore it, not 0.'''\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#hyperparameters\n",
    "learning_rate = 3e-4 #the paper quotes rmsprop with 0.1 lr, but we have a tiny batch size, and are using AdamW\n",
    "batch_size = 2 #the paper quotes 128 images/chip, but with video we have to change this\n",
    "max_iters = 1000\n",
    "eval_interval = 2\n",
    "weight_decay = 0.0005\n",
    "momentum = 0.9\n",
    "eps = np.sqrt(0.002) #From the pytorch blog post, \"a reasonable approximation can be taken with the formula PyTorch_eps = sqrt(TF_eps).\"\n",
    "std = torch.tensor([0.2104*255, 0.1986*255, 0.1829*255])[None,None,None,:]\n",
    "mean = torch.tensor([0.3939*255, 0.3817*255, 0.3314*255])[None,None,None,:]\n",
    "use_autocast = True\n",
    "\n",
    "#information for the dali pipeline\n",
    "sequence_length = 276 #longest videos in our dataset\n",
    "initial_prefetch_size = 1000\n",
    "\n",
    "#video paths\n",
    "train_video_paths = '/home/hankhome/Documents/PythonProjects/picklebotdataset/train'\n",
    "val_video_paths = '/home/hankhome/Documents/PythonProjects/picklebotdataset/val'\n",
    "num_train_videos = len(os.listdir(train_video_paths + '/' + 'balls')) + len(os.listdir(train_video_paths + '/' + 'strikes'))\n",
    "num_val_videos = len(os.listdir(val_video_paths + '/' + 'balls')) + len(os.listdir(val_video_paths + '/' + 'strikes'))\n",
    "#define our model, initialize\n",
    "model = MobileNetSmall3D().to(device)\n",
    "# initialize_mobilenet_weights(model)\n",
    "\n",
    "#for multi-gpu setups \n",
    "#may want to revisit this and choose which device we use for loading with dali, and which to use for training the net.\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "#define our optimizer\n",
    "#optimizer = optim.RMSprop(params=model.parameters(),lr=learning_rate,weight_decay=weight_decay,momentum=momentum,eps=eps) #starting with AdamW for now. \n",
    "optimizer = optim.AdamW(params=model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss() #we'll want to add back in ignoring the padding\n",
    "scaler = GradScaler()\n",
    "model_name = 'mobilenetsmall_3D_cloud' \n",
    "\n",
    "\n",
    "#estimate_loss using validation set, we should refactor this.\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    #evaluate the model\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_correct = 0\n",
    "    val_samples = 0\n",
    "\n",
    "    #calculate the loss\n",
    "    for _,val_features in tqdm(enumerate(val_loader)):\n",
    "        val_labels = (val_features[0]['label']).view(-1).long() #need this as a (batch_size,) tensor\n",
    "        val_features = val_features[0]['data']/255\n",
    "        val_features = (val_features-mean.to(device))/std.to(device) #normalize\n",
    "        val_features = val_features.permute(0,-1,1,2,3) \n",
    "        # val_labels = val_labels.expand(val_features.shape[2]) #this is only for our lstm T -> batch size, a lame hack\n",
    "\n",
    "        val_outputs = model(val_features)\n",
    "        \n",
    "        val_loss = criterion(val_outputs,val_labels)\n",
    "        \n",
    "        val_losses.append(val_loss.item())  \n",
    "        \n",
    "        val_correct += calculate_accuracy(val_outputs,val_labels) #get number of correct\n",
    "        val_samples += len(labels) #this is the total number of samples so far\n",
    "\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    val_accuracy = val_correct / val_samples\n",
    "    return avg_val_loss, val_accuracy\n",
    "\n",
    "\n",
    "#initialize lists for plotting\n",
    "start_time = time.time()\n",
    "train_losses = []\n",
    "train_percent = []\n",
    "val_losses = []\n",
    "val_percent = []\n",
    "\n",
    "#plot losses\n",
    "plt.ion()\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12,4))\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Val Loss')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "#plot accuracy\n",
    "ax2.plot(train_percent, label='Train Accuracy')\n",
    "ax2.plot(val_percent, label='Val Accuracy')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "#build our pipelines\n",
    "train_pipe = video_pipeline(batch_size=batch_size, num_threads=cpu_count(), device_id=0, file_root=train_video_paths,sequence_length=sequence_length,initial_prefetch_size=initial_prefetch_size)\n",
    "val_pipe = video_pipeline(batch_size=batch_size, num_threads=cpu_count(), device_id=0, file_root=val_video_paths,sequence_length=sequence_length,initial_prefetch_size=initial_prefetch_size)\n",
    "\n",
    "train_pipe.build()\n",
    "val_pipe.build()\n",
    "\n",
    "\n",
    "train_loader = DALIClassificationIterator(train_pipe, size=num_train_videos,auto_reset=True,last_batch_policy=LastBatchPolicy.PARTIAL)\n",
    "val_loader = DALIClassificationIterator(train_pipe, size=num_val_videos,auto_reset=True,last_batch_policy=LastBatchPolicy.PARTIAL)\n",
    "\n",
    "try:\n",
    "    for iter in range(max_iters):\n",
    "        \n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_samples = 0\n",
    "        batch_loss_list = [] #want to overwrite this each epoch\n",
    "        \n",
    "        #forward pass\n",
    "        for batch_idx, features in tqdm(enumerate(train_loader)):\n",
    "            \n",
    "            labels = (features[0]['label']).view(-1).long() #need this as a (batch_size,) tensor in int64\n",
    "            features = features[0]['data']/255 #i think it makes sense to overwrite features to save precious gpu memory\n",
    "            features = (features-mean.to(device))/std.to(device) #normalize\n",
    "\n",
    "\n",
    "            features = features.permute(0,-1,1,2,3)\n",
    "            # labels = labels.expand(features.shape[2]) #this is only for our lstm T -> batch size, a lame hack\n",
    "            \n",
    "            #zero the gradients\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if use_autocast:    \n",
    "                with autocast():\n",
    "                    outputs = model(features)\n",
    "                    loss = criterion(outputs,labels)\n",
    "                \n",
    "                #backprop & update weights\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            else:\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs,labels)\n",
    "\n",
    "                #backprop & update weights\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            batch_loss_list.append(loss.item()) #append the loss of the batch to our list to be averaged and plotted later, this is dataset size / batch size long\n",
    "            batch_correct = calculate_accuracy(outputs,labels) #number of correct predictions in the batch\n",
    "            train_correct += batch_correct #this is the total number of correct predictions so far\n",
    "            train_samples += len(labels) #this is the total number of samples so far\n",
    "\n",
    "\n",
    "        train_losses.append(np.mean(batch_loss_list))\n",
    "        train_percent.append(train_correct / train_samples)\n",
    "        elapsed = time.time() - start_time\n",
    "        remaining_iters = max_iters - iter\n",
    "        avg_time_per_iter = elapsed / (iter + 1)\n",
    "        estimated_remaining_time = remaining_iters * avg_time_per_iter\n",
    "\n",
    "\n",
    "        if iter !=0 and (iter % eval_interval == 0 or iter == max_iters - 1):\n",
    "            \n",
    "            #evaluate the model\n",
    "            val_loss, val_accuracy = estimate_loss()\n",
    "        \n",
    "            val_losses.append(val_loss) #loss of the val set\n",
    "            val_percent.append(val_accuracy) #percent of correct predictions in the val set\n",
    "\n",
    "\n",
    "            print(f\"step {iter}: train loss:  {train_losses[-1]:.4f}, val loss: {val_loss:.4f}\")\n",
    "            print(f\"step {iter}: train accuracy:  {train_percent[-1]*100:.2f}%, val accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "\n",
    "            # #plot the losses\n",
    "            ax1.plot(torch.tensor(train_losses).view(-1,1000).mean(1), label='Train Loss')\n",
    "            ax1.plot(torch.tensor(val_losses).view(-1,1000)(-1,1000).mean(1), label='Val Loss')\n",
    "\n",
    "            #plot the accuracy\n",
    "            ax2.plot(train_percent, label='Train Accuracy')\n",
    "            ax2.plot(val_percent, label='Val Accuracy')\n",
    "\n",
    "\n",
    "            fig.canvas.draw()\n",
    "            fig.canvas.flush_events()\n",
    "            plt.pause(0.001)\n",
    "\n",
    "        tqdm.write(f\"Iter [{iter+1}/{max_iters}] - Elapsed Time: {elapsed:.2f}s  Remaining Time: [{estimated_remaining_time:.2f}]\")\n",
    "        if iter == max_iters -1:\n",
    "            print(\"Training completed:\") \n",
    "            print(f\"Final train loss: {train_losses[-1]:.4f},\")\n",
    "            print(f\"Final val loss: {val_losses[-1]:.4f}, \")\n",
    "            print(f\"Final train accuracy: {train_percent[-1]*100:.2f}%, \")\n",
    "            print(f\"Final val accuracy: {val_percent[-1]*100:.2f}%\") \n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"Keyboard interrupt,\\nFinal train loss: {train_losses[-1]:.4f}, \")\n",
    "    print(f\"Final val loss: {val_losses[-1]:.4f}, \")\n",
    "    print(f\"Final train accuracy: {train_percent[-1]*100:.2f}%, \")\n",
    "    print(f\"Final val accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "\n",
    "finally:\n",
    "    torch.save(model.state_dict(), f'{model_name}.pth')\n",
    "    with open(f'{model_name}_train_losses.npy', 'wb') as f:\n",
    "        np.save(f, np.array(train_losses))\n",
    "    with open(f'{model_name}_val_losses.npy', 'wb') as f:\n",
    "        np.save(f, np.array(val_losses))\n",
    "    with open(f'{model_name}_train_percent.npy', 'wb') as f:\n",
    "        np.save(f, np.array(train_percent))\n",
    "    with open(f'{model_name}_val_percent.npy', 'wb') as f:\n",
    "        np.save(f, np.array(val_percent))\n",
    "    print(f\"Model saved!\") \n",
    "plt.ioff()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
