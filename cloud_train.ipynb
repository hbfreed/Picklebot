{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "from psutil import cpu_count\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader import PicklebotDataset, custom_collate\n",
    "from mobilenet import MobileNetLarge2D, MobileNetSmall2D, MobileNetSmall3D,MobileNetLarge3D\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "'''Balls are 0, strikes are 1'''\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#hyperparameters\n",
    "\n",
    "learning_rate = 3e-4 #the paper quotes rmsprop with 0.1 lr, but we have a tiny batch size, and are using AdamW\n",
    "batch_size = 64 #the paper quotes 128 images/chip, but with video we have to change this\n",
    "max_iters = 2000\n",
    "eval_interval = 50\n",
    "weight_decay=0.0005\n",
    "momentum=0.9\n",
    "eps=np.sqrt(0.002) #From the pytorch blog post, \"a reasonable approximation can be taken with the formula PyTorch_eps = sqrt(TF_eps).\"\n",
    "\n",
    "#annotations paths\n",
    "train_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/training_test/training_test_labels.csv'\n",
    "val_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/eval_test/eval_test_labels.csv'\n",
    "\n",
    "#video paths\n",
    "train_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/training_test'\n",
    "val_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/eval_test'\n",
    "\n",
    "#dataset     \n",
    "transform = transforms.Normalize((0.5,), (0.5,))\n",
    "\n",
    "train_dataset = PicklebotDataset(train_annotations_file,train_video_paths,transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "val_dataset = PicklebotDataset(val_annotations_file,val_video_paths,transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "\n",
    "#model, optimizer, loss function\n",
    "model = MobileNetSmall3D().to(device)\n",
    "\n",
    "#for multi-gpu\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# optimizer = optim.RMSprop(params=model.parameters(),lr=learning_rate,weight_decay=weight_decay,momentum=momentum,eps=eps) #starting with AdamW for now. \n",
    "optimizer = optim.AdamW(params=model.parameters(),lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=2)\n",
    "scaler = GradScaler()\n",
    "model_name = 'mobilenetsmall_3D_lambda' \n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    #evaluate the model\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    num_val_batches = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    #calculate the loss\n",
    "    for val_features,val_labels in val_loader:\n",
    "        val_features = val_features.to(device)\n",
    "        val_labels = val_labels.to(torch.int64) #waiting to move to device until after forward pass, idk if this matters\n",
    "        \n",
    "        val_outputs = model(val_features)\n",
    "        \n",
    "        val_loss = criterion(val_outputs,val_labels.to(device))\n",
    "        \n",
    "        total_val_loss += val_loss.item()\n",
    "        \n",
    "        num_val_batches += 1        \n",
    "        \n",
    "        correct_predictions += calculate_accuracy(val_outputs,val_labels)\n",
    "    \n",
    "    avg_val_loss = total_val_loss / num_val_batches\n",
    "    val_accuracy = correct_predictions / len(val_loader.dataset)\n",
    "    return avg_val_loss, val_accuracy\n",
    "\n",
    "def calculate_accuracy(outputs,labels):\n",
    "    predicted_classes = torch.argmax(outputs,dim=1).to(labels.device)\n",
    "    num_correct = torch.sum(predicted_classes == labels).item()\n",
    "    return num_correct\n",
    "\n",
    "\n",
    "\n",
    "#try except block so we can manually early stop while saving the model\n",
    "#training loop\n",
    "start_time = time.time()\n",
    "train_losses = []\n",
    "train_percent = []\n",
    "val_losses = []\n",
    "val_percent = []\n",
    "\n",
    "\n",
    "#plot losses\n",
    "plt.ion()\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12,4))\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Val Loss')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "#plot accuracy\n",
    "ax2.plot(train_percent, label='Train Accuracy')\n",
    "ax2.plot(val_percent, label='Val Accuracy')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "\n",
    "try:\n",
    "    for iter in range(max_iters):\n",
    "        \n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_samples = 0\n",
    "        #forward pass\n",
    "        for batch_idx, (features,labels) in tqdm(enumerate(train_loader)):\n",
    "            \n",
    "            labels = labels.to(torch.int64)\n",
    "            features = features.to(device)\n",
    "            \n",
    "            #zero the gradients\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs,labels.to(device))\n",
    "            \n",
    "            #backprop & update weights\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            batch_correct = calculate_accuracy(outputs,labels)\n",
    "            train_correct += batch_correct\n",
    "            train_samples += len(labels)\n",
    "\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "            \n",
    "            #evaluate the model\n",
    "            train_losses.append(loss.item()) #loss of the last batch\n",
    "            train_percent.append(train_correct / train_samples)\n",
    "            val_loss, val_accuracy = estimate_loss()\n",
    "        \n",
    "            val_losses.append(val_loss) #loss of the val batch\n",
    "            val_percent.append(val_accuracy) #percent of correct predictions in the val batch\n",
    "\n",
    "            print(f\"step {iter}: train loss:  {loss:.4f}, val loss: {val_loss:.4f}\")\n",
    "            print(f\"step {iter}: train accuracy:  {train_percent[-1]*100:.2f}%, eval accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "\n",
    "            # #plot the losses\n",
    "            ax1.plot(train_losses, label='Train Loss')\n",
    "            ax1.plot(val_losses, label='Val Loss')\n",
    "\n",
    "            #plot the accuracy\n",
    "            ax2.plot(train_percent, label='Train Accuracy')\n",
    "            ax2.plot(val_percent, label='Val Accuracy')\n",
    "\n",
    "\n",
    "            fig.canvas.draw()\n",
    "            fig.canvas.flush_events()\n",
    "            plt.pause(0.001)\n",
    "\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        remaining_iters = max_iters - iter\n",
    "        avg_time_per_iter = elapsed / (iter + 1)\n",
    "        estimated_remaining_time = remaining_iters * avg_time_per_iter\n",
    "\n",
    "        tqdm.write(f\"Iter [{iter+1}/{max_iters}] - Elapsed Time: {elapsed:.2f}s  Remaining Time: [{estimated_remaining_time:.2f}]\")\n",
    "        if iter == max_iters -1:\n",
    "            print(\"Training completed:\") \n",
    "            print(f\"Final train loss: {train_losses[-1]:.4f},\")\n",
    "            print(f\"Final val loss: {val_losses[-1]:.4f}, \")\n",
    "            print(f\"Final train accuracy: {train_percent[-1]*100:.2f}%, \")\n",
    "            print(f\"Final val accuracy: {val_percent[-1]*100:.2f}%\") \n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"Keyboard interrupt,\\nFinal train loss: {train_losses[-1]:.4f}, \")\n",
    "    print(f\"Final val loss: {val_losses[-1]:.4f}, \")\n",
    "    print(f\"Final train accuracy: {train_percent[-1]*100:.2f}%, \")\n",
    "    print(f\"Final val accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "\n",
    "finally:\n",
    "    torch.save(model.state_dict(), f'{model_name}.pth')\n",
    "    with open(f'{model_name}_train_losses.npy', 'wb') as f:\n",
    "        np.save(f, np.array(train_losses))\n",
    "    with open(f'{model_name}_val_losses.npy', 'wb') as f:\n",
    "        np.save(f, np.array(val_losses))\n",
    "    with open(f'{model_name}_train_percent.npy', 'wb') as f:\n",
    "        np.save(f, np.array(train_percent))\n",
    "    with open(f'{model_name}_val_percent.npy', 'wb') as f:\n",
    "        np.save(f, np.array(val_percent))\n",
    "    print(f\"Model saved!\") \n",
    "plt.ioff()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
