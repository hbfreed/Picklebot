{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''using torchvision for dataloading'''\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "from psutil import cpu_count\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dataloader import PicklebotDataset, custom_collate\n",
    "from mobilenet import MobileNetLarge2D, MobileNetSmall2D, MobileNetSmall3D,MobileNetLarge3D\n",
    "from movinet import MoViNetA2\n",
    "from helpers import calculate_accuracy, average_for_plotting\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#hyperparameters\n",
    "torch.manual_seed(1234)\n",
    "learning_rate = 3e-4 #we use cosine annealing so this is just a starting point\n",
    "batch_size = 2 #the paper quotes 128 images/chip, but with video we have to change this\n",
    "max_iters = 100\n",
    "eval_interval = 1\n",
    "weight_decay = 5e-4\n",
    "std = (0.2104, 0.1986, 0.1829)\n",
    "mean = (0.3939, 0.3817, 0.3314)\n",
    "use_autocast = False \n",
    "compile = False\n",
    "\n",
    "#video paths\n",
    "train_video_paths = '/workspace/picklebotdataset/train'\n",
    "val_video_paths = '/workspace/picklebotdataset/val'\n",
    "\n",
    "#annotations paths\n",
    "train_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/train_labels.csv'\n",
    "val_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/val_labels.csv'\n",
    "\n",
    "#video paths\n",
    "train_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/train_all_together'\n",
    "val_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/val_all_together'\n",
    "\n",
    "#establish our normalization using transforms, \n",
    "#note that we are doing this in our dataloader as opposed to in the training loop like with dali\n",
    "transform = transforms.Normalize(mean,std)\n",
    "\n",
    "#dataset     \n",
    "train_dataset = PicklebotDataset(train_annotations_file,train_video_paths,transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "val_dataset = PicklebotDataset(val_annotations_file,val_video_paths,transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "\n",
    "#define model, initialize weights \n",
    "model = MobileNetLarge3D()\n",
    "# model.initialize_weights()\n",
    "model = model.to(device)\n",
    "\n",
    "#for multi-gpu\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# optimizer\n",
    "# optimizer = optim.RMSprop(params=model.parameters(),lr=learning_rate,weight_decay=weight_decay,momentum=momentum,eps=eps) #starting with AdamW for now. \n",
    "optimizer = optim.AdamW(params=model.parameters(),lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "#cosine annealing\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "#loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if use_autocast:\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "model_name = model.__class__.__name__\n",
    "writer = SummaryWriter(f'runs/{model_name}') #tensorboard writer \n",
    "# checkpoint = torch.load('checkpoints/MobileNetLarge3D17.pth')\n",
    "# loaded_state_dict_keys = checkpoint.keys()\n",
    "# updated_state_dict = {}\n",
    "# for key,value in checkpoint.items():\n",
    "#     new_key = key.replace('_orig_mod.','') #remove the prefix\n",
    "#     updated_state_dict[new_key] = value\n",
    "# model.load_state_dict(updated_state_dict)\n",
    "\n",
    "\n",
    "if compile:\n",
    "    print(\"compiling the model... (takes a ~minute)\")\n",
    "    unoptimized_model = model\n",
    "    model = torch.compile(model)  # requires PyTorch 2 and a modern gpu, these lines are from karpathy\n",
    "    print(\"compilation complete!\")\n",
    "\n",
    "\n",
    "#estimate loss using the val set, and calculate accuracy\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    #evaluate the model\n",
    "    model.eval()\n",
    "    val_losses = [] \n",
    "    val_correct = 0\n",
    "    val_samples = 0\n",
    "\n",
    "    #calculate the loss\n",
    "    for val_features,val_labels in tqdm(val_loader):\n",
    "        val_features = val_features.to(device)\n",
    "        val_labels = val_labels.long() #waiting to move to device until after forward pass, idk if this matters\n",
    "        # val_labels = val_labels.expand(val_features.shape[2]) #this is only for our lstm T -> batch size, a lame hack    \n",
    "        val_outputs = model(val_features)\n",
    "\n",
    "        val_loss = criterion(val_outputs,val_labels.to(device))\n",
    "        val_losses.append(val_loss.item())\n",
    "        \n",
    "        val_correct += calculate_accuracy(val_outputs,val_labels)\n",
    "        val_samples += len(val_labels)\n",
    "\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    val_accuracy = val_correct / val_samples\n",
    "    return avg_val_loss, val_accuracy\n",
    "\n",
    "#try except block so we can manually early stop while saving the model\n",
    "#training loop\n",
    "start_time = time.time()\n",
    "train_losses = torch.tensor([])\n",
    "train_percent = torch.tensor([])\n",
    "val_losses = []\n",
    "val_percent = []\n",
    "counter = 0\n",
    "\n",
    "try:\n",
    "    for iter in range(max_iters):\n",
    "        \n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_samples = 0\n",
    "        batch_loss_list = []\n",
    "        batch_percent_list = []\n",
    "\n",
    "        #forward pass\n",
    "        for batch_idx, (features,labels) in tqdm(enumerate(train_loader)):\n",
    "            labels = labels.to(torch.int64)\n",
    "            features = features.to(device)\n",
    "            # labels = labels.expand(features.shape[2]) #this is only for our lstm T -> batch size, a lame hack\n",
    "            \n",
    "            #zero the gradients\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if use_autocast:    \n",
    "                with autocast():\n",
    "                    outputs = model(features)\n",
    "                    loss = criterion(outputs,labels.to(device))\n",
    "                \n",
    "                #backprop & update weights\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            else:\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs,labels.to(device))\n",
    "\n",
    "                #backprop & update weights\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            \n",
    "\n",
    "            batch_loss_list.append(loss.item()) #append the loss of the batch to our list to be averaged and plotted later, this is dataset size / batch size long\n",
    "            batch_correct = calculate_accuracy(outputs,labels) #number of correct predictions in the batch\n",
    "            train_correct += batch_correct #this is the total number of correct predictions so far\n",
    "            train_samples += len(labels) #this is the total number of samples so far\n",
    "            batch_percent_list.append(train_correct/train_samples)\n",
    "            writer.add_scalar('training loss', batch_loss_list[-1], counter)\n",
    "            writer.add_scalar('training accuracy', batch_percent_list[-1], counter)\n",
    "            counter += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        train_losses = torch.cat((train_losses,average_for_plotting(batch_loss_list))) #train losses is a tensor\n",
    "        train_percent = torch.cat((train_percent,average_for_plotting(batch_percent_list))) #train percent is a tensor\n",
    "        elapsed = time.time() - start_time\n",
    "        remaining_iters = max_iters - iter\n",
    "        avg_time_per_iter = elapsed / (iter + 1)\n",
    "        estimated_remaining_time = remaining_iters * avg_time_per_iter\n",
    "\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "                        \n",
    "            #evaluate the model\n",
    "            val_loss, val_accuracy = estimate_loss()\n",
    "        \n",
    "            val_losses.append(val_loss) #average loss of the val dataset, this is a scalar\n",
    "            val_percent.append(val_accuracy) #percent of correct predictions in the val set, this is a scalar\n",
    "\n",
    "\n",
    "            print(f\"step {iter}: train loss:  {train_losses[-1].mean().item():.4f}, val loss: {val_losses[-1]:.4f}\") #report the average loss of the batch\n",
    "            print(f\"step {iter}: train accuracy:  {(train_percent[-1].mean().item())*100:.2f}%, val accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "            writer.add_scalar('val loss', val_losses[-1], iter)\n",
    "            writer.add_scalar('val accuracy',val_percent[-1], iter)\n",
    "            torch.save(model.state_dict(), f'checkpoints/{model_name}{iter}.pth')\n",
    "\n",
    "        tqdm.write(f\"Iter [{iter+1}/{max_iters}] - Elapsed Time: {elapsed:.2f}s  Remaining Time: [{estimated_remaining_time:.2f}]\")\n",
    "        if iter == max_iters -1:\n",
    "            print(\"Training completed:\") \n",
    "            print(f\"Final train loss: {train_losses[-1].mean().item():.4f},\")\n",
    "            print(f\"Final val loss: {val_losses[-1]:.4f}, \")\n",
    "            print(f\"Final train accuracy: {(train_percent[-1].mean().item())*100:.2f}%, \")\n",
    "            print(f\"Final val accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"Keyboard interrupt,\\nFinal train loss: {train_losses[-1].mean().item():.4f}, \")\n",
    "    print(f\"Final val loss: {val_losses[-1]:.4f}, \")\n",
    "    print(f\"Final train accuracy: {(train_percent[-1].mean().item())*100:.2f}%, \")\n",
    "    print(f\"Final val accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "\n",
    "finally:\n",
    "    torch.save(model.state_dict(), f'checkpoints/{model_name}_finished.pth')\n",
    "    with open(f'statistics/{model_name}_finished_train_losses.npy', 'wb') as f:\n",
    "        np.save(f, np.array(train_losses))\n",
    "    with open(f'statistics/{model_name}_finished_val_losses.npy', 'wb') as f:\n",
    "        np.save(f, np.array(val_losses))\n",
    "    with open(f'statistics/{model_name}_finished_train_percent.npy', 'wb') as f:\n",
    "        np.save(f, np.array(train_percent))\n",
    "    with open(f'statistics/{model_name}_finished_val_percent.npy', 'wb') as f:\n",
    "        np.save(f, np.array(val_percent))\n",
    "    print(f\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This version of the program uses Nvidia Dali to load data, not torchvision.io.read_video,\n",
    "   It should be substantially faster, especially with multiple gpus, perhaps a good setup \n",
    "   would be one to load the videos, one to run the training loop? Perhaps not as I learned more about it.\n",
    "\n",
    "    Eventually, this and the other version in this notebook should be merged into one notebook, with a flag to choose which to use.\n",
    "   \n",
    "'''\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from nvidia.dali.plugin.pytorch import DALIClassificationIterator, LastBatchPolicy\n",
    "from tqdm import tqdm\n",
    "from psutil import cpu_count\n",
    "from mobilenet import MobileNetLarge2D, MobileNetSmall2D, MobileNetSmall3D, MobileNetLarge3D\n",
    "from movinet import MoViNetA2\n",
    "from helpers import calculate_accuracy, video_pipeline, average_for_plotting\n",
    "\n",
    "'''\n",
    "Our mean is ([0.3939, 0.3817, 0.3314])\n",
    "Our std is ([0.2104, 0.1986, 0.1829])\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''Strikes are 0, balls 1.'''\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16\n",
    "#hyperparameters\n",
    "learning_rate = 3e-4 #the paper quotes rmsprop with 0.1 lr, but we have a tiny batch size, and are using AdamW\n",
    "batch_size = 64 #the paper quotes 128 images/chip, but with video we have to change this\n",
    "max_iters = 100\n",
    "eval_interval = 1\n",
    "weight_decay = 0.0005\n",
    "momentum = 0.9\n",
    "eps = np.sqrt(0.002) #From the pytorch blog post, \"a reasonable approximation can be taken with the formula PyTorch_eps = sqrt(TF_eps).\"\n",
    "std = torch.tensor([0.2104, 0.1986, 0.1829])[None,None,None,:]\n",
    "mean = torch.tensor([0.3539, 0.3817, 0.3314])[None,None,None,:]\n",
    "use_autocast = True\n",
    "compile = False\n",
    "\n",
    "#information for the dali pipeline\n",
    "sequence_length = 130 #longest videos in our dataset \n",
    "initial_prefetch_size = 20\n",
    "\n",
    "#video paths\n",
    "train_video_paths = '/workspace/picklebotdataset/train'\n",
    "val_video_paths = '/workspace/picklebotdataset/val'\n",
    "\n",
    "num_train_videos = len(os.listdir(train_video_paths + '/' + 'balls')) + len(os.listdir(train_video_paths + '/' + 'strikes'))\n",
    "num_val_videos = len(os.listdir(val_video_paths + '/' + 'balls')) + len(os.listdir(val_video_paths + '/' + 'strikes'))\n",
    "\n",
    "#define our model, initialize weights\n",
    "model = MoViNetA2()\n",
    "model.initialize_weights()\n",
    "model = model.to(device)\n",
    "\n",
    "#for multi-gpu setups \n",
    "#may want to revisit this and choose which device we use for loading with dali, and which to use for training the net.\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "#define our optimizer\n",
    "#optimizer = optim.RMSprop(params=model.parameters(),lr=learning_rate,weight_decay=weight_decay,momentum=momentum,eps=eps) #starting with AdamW for now. \n",
    "optimizer = optim.AdamW(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "#cosine annealing\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "#loss\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "if use_autocast:\n",
    "    scaler = GradScaler()\n",
    "model_name = model.__class__.__name__ \n",
    "writer = SummaryWriter(f'runs/{model_name}') #tensorboard writer\n",
    "# model.load_state_dict(torch.load(f'{model_name}.pth')) #if applicable, load the model from the last checkpoint\n",
    "\n",
    "\n",
    "if compile:\n",
    "    print(\"compiling the model... (takes a ~minute)\")\n",
    "    unoptimized_model = model\n",
    "    model = torch.compile(model)  # requires PyTorch 2 and a modern gpu, these lines were lifted from karpathy\n",
    "    print(\"compilation complete!\")\n",
    "\n",
    "#estimate_loss using validation set, we should refactor this.\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    #evaluate the model\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_correct = 0\n",
    "    val_samples = 0\n",
    "\n",
    "    #calculate the loss\n",
    "    for _,val_features in tqdm(enumerate(val_loader)):\n",
    "        val_labels = (val_features[0]['label']).view(-1).long() #need this as a (batch_size,) tensor\n",
    "        val_features = val_features[0]['data']/255\n",
    "        val_features = val_features.permute(0,-1,1,2,3) \n",
    "        # val_labels = val_labels.expand(val_features.shape[2]) #this is only for our lstm T -> batch size, a lame hack\n",
    "\n",
    "        val_outputs = model(val_features)\n",
    "        \n",
    "        val_loss = criterion(val_outputs,val_labels)\n",
    "        \n",
    "        val_losses.append(val_loss.item())  \n",
    "        \n",
    "        val_correct += calculate_accuracy(val_outputs,val_labels) #get number of correct\n",
    "        val_samples += len(labels) #this is the total number of samples so far\n",
    "\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    val_accuracy = val_correct / val_samples\n",
    "    return avg_val_loss, val_accuracy\n",
    "\n",
    "\n",
    "#initialize lists for plotting\n",
    "start_time = time.time()\n",
    "train_losses = torch.tensor([])\n",
    "train_percent = torch.tensor([])\n",
    "val_losses = []\n",
    "val_percent = []\n",
    "counter = 0\n",
    "\n",
    "#build our pipelines\n",
    "train_pipe = video_pipeline(batch_size=batch_size, num_threads=cpu_count(), device_id=0, file_root=train_video_paths,\n",
    "                            sequence_length=sequence_length,initial_prefetch_size=initial_prefetch_size,mean=mean,std=std)\n",
    "val_pipe = video_pipeline(batch_size=batch_size, num_threads=cpu_count(), device_id=0, file_root=val_video_paths,\n",
    "                          sequence_length=sequence_length,initial_prefetch_size=initial_prefetch_size,mean=mean,std=std)\n",
    "\n",
    "train_pipe.build()\n",
    "val_pipe.build()\n",
    "\n",
    "\n",
    "train_loader = DALIClassificationIterator(train_pipe, auto_reset=True,last_batch_policy=LastBatchPolicy.PARTIAL, size=num_train_videos)\n",
    "val_loader = DALIClassificationIterator(val_pipe, auto_reset=True,last_batch_policy=LastBatchPolicy.PARTIAL, size=num_val_videos)\n",
    "\n",
    "try:\n",
    "    for iter in range(max_iters):\n",
    "        \n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_samples = 0\n",
    "        batch_loss_list = [] #want to overwrite this each epoch\n",
    "        batch_percent_list = []\n",
    "\n",
    "        #forward pass\n",
    "        for batch_idx, features in tqdm(enumerate(train_loader)):\n",
    "            \n",
    "            labels = (features[0]['label']).view(-1).long() #need this as a (batch_size,) tensor in int64\n",
    "            features = features[0]['data']/255 #i think it makes sense to overwrite features to save precious gpu memory\n",
    "            features = features.permute(0,-1,1,2,3) #reshape for our 3D convolutions\n",
    "            # labels = labels.expand(features.shape[2]) #this is only for our lstm T -> batch size, a lame hack\n",
    "            \n",
    "            #zero the gradients\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if use_autocast:    \n",
    "                with autocast(dtype=dtype):\n",
    "                    outputs = model(features)\n",
    "                    loss = criterion(outputs,labels)\n",
    "                \n",
    "                #backprop & update weights\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            else:\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs,labels)\n",
    "\n",
    "                #backprop & update weights\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            #step the scheduler after the epoch\n",
    "            scheduler.step()\n",
    "            batch_loss_list.append(loss.item()) #append the loss of the batch to our list to be averaged and plotted later, this is dataset size / batch size long\n",
    "            batch_correct = calculate_accuracy(outputs,labels) #number of correct predictions in the batch\n",
    "            train_correct += batch_correct #this is the total number of correct predictions so far\n",
    "            train_samples += len(labels) #this is the total number of samples so far\n",
    "            batch_percent_list.append(train_correct/train_samples)\n",
    "            writer.add_scalar('training loss', batch_loss_list[-1], counter)\n",
    "            writer.add_scalar('training accuracy', batch_percent_list[-1], counter)\n",
    "            counter += 1\n",
    "\n",
    "        train_losses = torch.cat((train_losses,average_for_plotting(batch_loss_list))) #train losses is a tensor\n",
    "        train_percent = torch.cat((train_percent,average_for_plotting(batch_percent_list))) #train percent is a tensor\n",
    "        elapsed = time.time() - start_time\n",
    "        remaining_iters = max_iters - iter\n",
    "        avg_time_per_iter = elapsed / (iter + 1)\n",
    "        estimated_remaining_time = remaining_iters * avg_time_per_iter\n",
    "\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "                        \n",
    "            #evaluate the model\n",
    "            val_loss, val_accuracy = estimate_loss()\n",
    "        \n",
    "            val_losses.append(val_loss) #average loss of the val dataset, this is a scalar\n",
    "            val_percent.append(val_accuracy) #percent of correct predictions in the val set, this is a scalar\n",
    "\n",
    "\n",
    "            print(f\"step {iter}: train loss:  {train_losses[-1].mean().item():.4f}, val loss: {val_losses[-1]:.4f}\") #report the average loss of the batch\n",
    "            print(f\"step {iter}: train accuracy:  {(train_percent[-1].mean().item())*100:.2f}%, val accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "            writer.add_scalar('val loss', val_losses[-1], iter)\n",
    "            writer.add_scalar('val accuracy',val_percent[-1], iter)\n",
    "            torch.save(model.state_dict(), f'checkpoints/{model_name}{iter}.pth')\n",
    "\n",
    "        tqdm.write(f\"Iter [{iter+1}/{max_iters}] - Elapsed Time: {elapsed:.2f}s  Remaining Time: [{estimated_remaining_time:.2f}]\")\n",
    "        if iter == max_iters -1:\n",
    "            print(\"Training completed:\") \n",
    "            print(f\"Final train loss: {train_losses[-1].mean().item():.4f},\")\n",
    "            print(f\"Final val loss: {val_losses[-1]:.4f}, \")\n",
    "            print(f\"Final train accuracy: {(train_percent[-1].mean().item())*100:.2f}%, \")\n",
    "            print(f\"Final val accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"Keyboard interrupt,\\nFinal train loss: {train_losses[-1].mean().item():.4f}, \")\n",
    "    print(f\"Final val loss: {val_losses[-1]:.4f}, \")\n",
    "    print(f\"Final train accuracy: {(train_percent[-1].mean().item())*100:.2f}%, \")\n",
    "    print(f\"Final val accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "\n",
    "finally:\n",
    "    torch.save(model.state_dict(), f'checkpoints/{model_name}_finished.pth')\n",
    "    with open(f'statistics/{model_name}_finished_train_losses.npy', 'wb') as f:\n",
    "        np.save(f, np.array(train_losses))\n",
    "    with open(f'statistics/{model_name}_finished_val_losses.npy', 'wb') as f:\n",
    "        np.save(f, np.array(val_losses))\n",
    "    with open(f'statistics/{model_name}_finished_train_percent.npy', 'wb') as f:\n",
    "        np.save(f, np.array(train_percent))\n",
    "    with open(f'statistics/{model_name}_finished_val_percent.npy', 'wb') as f:\n",
    "        np.save(f, np.array(val_percent))\n",
    "    print(f\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10773it [2:34:21,  1.16it/s]\n",
      "/home/henry/Documents/PythonProjects/Picklebot/helpers.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  avg_losses = torch.tensor(loss_list[:-partial_size]).view(-1,1000).mean(1)\n",
      "/home/henry/Documents/PythonProjects/Picklebot/helpers.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  avg_partial = torch.tensor(loss_list[-partial_size:]).view(-1,partial_size).mean(1)\n",
      "100%|██████████| 1348/1348 [19:54<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Train Loss: 0.6934, Val Loss: 0.6932\n",
      "Step 0: Train Accuracy: 49.55%, Val Accuracy: 49.94%\n",
      "Iter [1/100] - Elapsed Time: 9261.69s - Remaining Time: [926168.86]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:34:10,  1.16it/s]\n",
      "100%|██████████| 1348/1348 [19:53<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Train Loss: 0.6935, Val Loss: 0.6932\n",
      "Step 1: Train Accuracy: 48.58%, Val Accuracy: 50.04%\n",
      "Iter [2/100] - Elapsed Time: 19707.00s - Remaining Time: [975496.30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:34:17,  1.16it/s]\n",
      "100%|██████████| 1348/1348 [19:49<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Train Loss: 0.6933, Val Loss: 0.6932\n",
      "Step 2: Train Accuracy: 49.06%, Val Accuracy: 49.70%\n",
      "Iter [3/100] - Elapsed Time: 30158.29s - Remaining Time: [985170.82]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:34:15,  1.16it/s]\n",
      "100%|██████████| 1348/1348 [20:00<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Train Loss: 0.6932, Val Loss: 0.6953\n",
      "Step 3: Train Accuracy: 51.03%, Val Accuracy: 50.04%\n",
      "Iter [4/100] - Elapsed Time: 40603.71s - Remaining Time: [984640.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:40:17,  1.12it/s]\n",
      "100%|██████████| 1348/1348 [20:20<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Train Loss: 0.6934, Val Loss: 0.6932\n",
      "Step 4: Train Accuracy: 50.03%, Val Accuracy: 50.24%\n",
      "Iter [5/100] - Elapsed Time: 51421.38s - Remaining Time: [987290.51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:33:49,  1.17it/s]\n",
      "100%|██████████| 1348/1348 [19:56<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Train Loss: 0.6930, Val Loss: 0.6932\n",
      "Step 5: Train Accuracy: 50.06%, Val Accuracy: 50.48%\n",
      "Iter [6/100] - Elapsed Time: 61872.14s - Remaining Time: [979642.30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:34:39,  1.16it/s]\n",
      "100%|██████████| 1348/1348 [19:52<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Train Loss: 0.6931, Val Loss: 0.6935\n",
      "Step 6: Train Accuracy: 51.20%, Val Accuracy: 51.71%\n",
      "Iter [7/100] - Elapsed Time: 72348.92s - Remaining Time: [971542.61]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:34:34,  1.16it/s]\n",
      "100%|██████████| 1348/1348 [19:57<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7: Train Loss: 0.6850, Val Loss: 0.6841\n",
      "Step 7: Train Accuracy: 55.85%, Val Accuracy: 55.16%\n",
      "Iter [8/100] - Elapsed Time: 82816.03s - Remaining Time: [962736.34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:57,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:40<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8: Train Loss: 0.6731, Val Loss: 0.6788\n",
      "Step 8: Train Accuracy: 57.15%, Val Accuracy: 56.82%\n",
      "Iter [9/100] - Elapsed Time: 93071.00s - Remaining Time: [951392.48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:29:52,  1.20it/s]\n",
      "100%|██████████| 1348/1348 [19:45<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9: Train Loss: 0.6686, Val Loss: 0.6767\n",
      "Step 9: Train Accuracy: 58.70%, Val Accuracy: 58.49%\n",
      "Iter [10/100] - Elapsed Time: 103244.83s - Remaining Time: [939527.92]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:18,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:39<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: Train Loss: 0.6594, Val Loss: 0.7025\n",
      "Step 10: Train Accuracy: 58.83%, Val Accuracy: 61.20%\n",
      "Iter [11/100] - Elapsed Time: 113509.73s - Remaining Time: [928716.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:51,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:39<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11: Train Loss: 0.6444, Val Loss: 0.6959\n",
      "Step 11: Train Accuracy: 61.71%, Val Accuracy: 60.66%\n",
      "Iter [12/100] - Elapsed Time: 123741.17s - Remaining Time: [917746.98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:55,  1.18it/s]\n",
      "100%|██████████| 1348/1348 [19:44<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12: Train Loss: 0.6329, Val Loss: 0.6420\n",
      "Step 12: Train Accuracy: 62.55%, Val Accuracy: 61.83%\n",
      "Iter [13/100] - Elapsed Time: 134037.01s - Remaining Time: [907327.46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:32:08,  1.18it/s]\n",
      "100%|██████████| 1348/1348 [19:45<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13: Train Loss: 0.6353, Val Loss: 0.6321\n",
      "Step 13: Train Accuracy: 63.78%, Val Accuracy: 64.35%\n",
      "Iter [14/100] - Elapsed Time: 144350.44s - Remaining Time: [897034.90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:32:13,  1.18it/s]\n",
      "100%|██████████| 1348/1348 [19:51<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14: Train Loss: 0.6197, Val Loss: 0.6329\n",
      "Step 14: Train Accuracy: 64.62%, Val Accuracy: 62.04%\n",
      "Iter [15/100] - Elapsed Time: 154669.16s - Remaining Time: [886769.84]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:32:31,  1.18it/s]\n",
      "100%|██████████| 1348/1348 [19:54<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15: Train Loss: 0.6151, Val Loss: 0.6056\n",
      "Step 15: Train Accuracy: 65.49%, Val Accuracy: 66.47%\n",
      "Iter [16/100] - Elapsed Time: 165012.53s - Remaining Time: [876629.06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:14,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:40<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16: Train Loss: 0.6001, Val Loss: 0.6132\n",
      "Step 16: Train Accuracy: 67.66%, Val Accuracy: 66.08%\n",
      "Iter [17/100] - Elapsed Time: 175281.77s - Remaining Time: [866098.18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:26,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:48<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17: Train Loss: 0.5874, Val Loss: 0.6173\n",
      "Step 17: Train Accuracy: 68.47%, Val Accuracy: 67.16%\n",
      "Iter [18/100] - Elapsed Time: 185549.33s - Remaining Time: [855588.59]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:11,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:35<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18: Train Loss: 0.5866, Val Loss: 0.5927\n",
      "Step 18: Train Accuracy: 68.86%, Val Accuracy: 68.53%\n",
      "Iter [19/100] - Elapsed Time: 195809.56s - Remaining Time: [845072.86]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:11,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:31<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19: Train Loss: 0.5788, Val Loss: 0.5760\n",
      "Step 19: Train Accuracy: 69.47%, Val Accuracy: 69.10%\n",
      "Iter [20/100] - Elapsed Time: 206056.87s - Remaining Time: [834530.34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:46,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:35<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20: Train Loss: 0.5735, Val Loss: 0.5730\n",
      "Step 20: Train Accuracy: 69.21%, Val Accuracy: 69.10%\n",
      "Iter [21/100] - Elapsed Time: 216275.65s - Remaining Time: [823907.24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:36,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:37<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21: Train Loss: 0.5622, Val Loss: 0.5735\n",
      "Step 21: Train Accuracy: 70.70%, Val Accuracy: 69.57%\n",
      "Iter [22/100] - Elapsed Time: 226488.88s - Remaining Time: [813300.98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:42,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:39<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22: Train Loss: 0.5641, Val Loss: 0.5557\n",
      "Step 22: Train Accuracy: 70.02%, Val Accuracy: 70.46%\n",
      "Iter [23/100] - Elapsed Time: 236709.16s - Remaining Time: [802752.80]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:48,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:39<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 23: Train Loss: 0.5527, Val Loss: 0.5762\n",
      "Step 23: Train Accuracy: 71.90%, Val Accuracy: 70.01%\n",
      "Iter [24/100] - Elapsed Time: 246937.56s - Remaining Time: [792257.99]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:41,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:40<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 24: Train Loss: 0.5515, Val Loss: 0.5905\n",
      "Step 24: Train Accuracy: 71.70%, Val Accuracy: 71.96%\n",
      "Iter [25/100] - Elapsed Time: 257158.34s - Remaining Time: [781761.34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:42,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:35<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 25: Train Loss: 0.5397, Val Loss: 0.6537\n",
      "Step 25: Train Accuracy: 72.09%, Val Accuracy: 72.53%\n",
      "Iter [26/100] - Elapsed Time: 267382.14s - Remaining Time: [771294.64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:33,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:36<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26: Train Loss: 0.5488, Val Loss: 0.5722\n",
      "Step 26: Train Accuracy: 71.86%, Val Accuracy: 72.13%\n",
      "Iter [27/100] - Elapsed Time: 277591.36s - Remaining Time: [760805.94]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:15,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:36<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 27: Train Loss: 0.5293, Val Loss: 0.6125\n",
      "Step 27: Train Accuracy: 73.74%, Val Accuracy: 72.74%\n",
      "Iter [28/100] - Elapsed Time: 287844.06s - Remaining Time: [750450.59]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:53,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:29<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 28: Train Loss: 0.5333, Val Loss: 0.5532\n",
      "Step 28: Train Accuracy: 73.19%, Val Accuracy: 72.76%\n",
      "Iter [29/100] - Elapsed Time: 298073.66s - Remaining Time: [740044.94]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:51,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:40<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 29: Train Loss: 0.5126, Val Loss: 0.5918\n",
      "Step 29: Train Accuracy: 73.90%, Val Accuracy: 73.15%\n",
      "Iter [30/100] - Elapsed Time: 308295.30s - Remaining Time: [729632.21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:23,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:35<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 30: Train Loss: 0.5194, Val Loss: 0.5513\n",
      "Step 30: Train Accuracy: 74.13%, Val Accuracy: 73.00%\n",
      "Iter [31/100] - Elapsed Time: 318499.44s - Remaining Time: [719192.28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:26,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:38<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31: Train Loss: 0.5120, Val Loss: 0.5623\n",
      "Step 31: Train Accuracy: 75.03%, Val Accuracy: 73.89%\n",
      "Iter [32/100] - Elapsed Time: 328762.35s - Remaining Time: [708893.81]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:21,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:24<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 32: Train Loss: 0.5110, Val Loss: 0.6003\n",
      "Step 32: Train Accuracy: 74.03%, Val Accuracy: 72.96%\n",
      "Iter [33/100] - Elapsed Time: 338962.42s - Remaining Time: [698468.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:42,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:27<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 33: Train Loss: 0.5038, Val Loss: 0.5695\n",
      "Step 33: Train Accuracy: 75.16%, Val Accuracy: 73.94%\n",
      "Iter [34/100] - Elapsed Time: 349169.76s - Remaining Time: [688069.81]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:36,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:38<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 34: Train Loss: 0.4882, Val Loss: 0.5514\n",
      "Step 34: Train Accuracy: 76.75%, Val Accuracy: 74.22%\n",
      "Iter [35/100] - Elapsed Time: 359373.75s - Remaining Time: [677676.21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:12,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:33<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 35: Train Loss: 0.4891, Val Loss: 0.6409\n",
      "Step 35: Train Accuracy: 76.94%, Val Accuracy: 73.57%\n",
      "Iter [36/100] - Elapsed Time: 369625.19s - Remaining Time: [667378.82]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:20,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:37<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 36: Train Loss: 0.4933, Val Loss: 0.6354\n",
      "Step 36: Train Accuracy: 77.01%, Val Accuracy: 75.13%\n",
      "Iter [37/100] - Elapsed Time: 379880.12s - Remaining Time: [657089.93]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:54,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:38<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 37: Train Loss: 0.5079, Val Loss: 0.5847\n",
      "Step 37: Train Accuracy: 74.45%, Val Accuracy: 75.37%\n",
      "Iter [38/100] - Elapsed Time: 390111.62s - Remaining Time: [646764.00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:14,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:37<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 38: Train Loss: 0.4931, Val Loss: 0.6426\n",
      "Step 38: Train Accuracy: 75.71%, Val Accuracy: 75.61%\n",
      "Iter [39/100] - Elapsed Time: 400365.17s - Remaining Time: [636477.96]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:26,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:32<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 39: Train Loss: 0.5002, Val Loss: 0.5374\n",
      "Step 39: Train Accuracy: 75.13%, Val Accuracy: 76.08%\n",
      "Iter [40/100] - Elapsed Time: 410569.73s - Remaining Time: [626118.83]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:53,  1.18it/s]\n",
      "100%|██████████| 1348/1348 [19:37<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 40: Train Loss: 0.4646, Val Loss: 0.5936\n",
      "Step 40: Train Accuracy: 77.62%, Val Accuracy: 75.80%\n",
      "Iter [41/100] - Elapsed Time: 420855.43s - Remaining Time: [615885.99]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:35,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:35<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 41: Train Loss: 0.4806, Val Loss: 0.7904\n",
      "Step 41: Train Accuracy: 76.78%, Val Accuracy: 74.33%\n",
      "Iter [42/100] - Elapsed Time: 431069.05s - Remaining Time: [605549.38]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:21,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:22<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 42: Train Loss: 0.4790, Val Loss: 0.6408\n",
      "Step 42: Train Accuracy: 76.07%, Val Accuracy: 76.76%\n",
      "Iter [43/100] - Elapsed Time: 441265.83s - Remaining Time: [595195.77]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:20,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:44<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 43: Train Loss: 0.4630, Val Loss: 0.7722\n",
      "Step 43: Train Accuracy: 77.20%, Val Accuracy: 76.06%\n",
      "Iter [44/100] - Elapsed Time: 451508.57s - Remaining Time: [584908.83]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:24,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:32<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 44: Train Loss: 0.4811, Val Loss: 0.5970\n",
      "Step 44: Train Accuracy: 76.71%, Val Accuracy: 76.84%\n",
      "Iter [45/100] - Elapsed Time: 461777.87s - Remaining Time: [574656.91]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:26,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:40<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 45: Train Loss: 0.4517, Val Loss: 0.8226\n",
      "Step 45: Train Accuracy: 78.01%, Val Accuracy: 76.26%\n",
      "Iter [46/100] - Elapsed Time: 472038.01s - Remaining Time: [564393.27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:00,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:40<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 46: Train Loss: 0.4636, Val Loss: 0.6604\n",
      "Step 46: Train Accuracy: 77.49%, Val Accuracy: 76.76%\n",
      "Iter [47/100] - Elapsed Time: 482279.53s - Remaining Time: [554108.40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:41,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:44<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 47: Train Loss: 0.4534, Val Loss: 0.7824\n",
      "Step 47: Train Accuracy: 77.46%, Val Accuracy: 76.22%\n",
      "Iter [48/100] - Elapsed Time: 492501.89s - Remaining Time: [543804.17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:59,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:30<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 48: Train Loss: 0.4556, Val Loss: 1.5593\n",
      "Step 48: Train Accuracy: 77.52%, Val Accuracy: 76.61%\n",
      "Iter [49/100] - Elapsed Time: 502746.55s - Remaining Time: [533526.95]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:55,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:35<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 49: Train Loss: 0.4453, Val Loss: 1.2938\n",
      "Step 49: Train Accuracy: 78.69%, Val Accuracy: 76.30%\n",
      "Iter [50/100] - Elapsed Time: 512972.97s - Remaining Time: [523232.43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:32,  1.18it/s]\n",
      "100%|██████████| 1348/1348 [19:36<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50: Train Loss: 0.4511, Val Loss: 1.3825\n",
      "Step 50: Train Accuracy: 78.30%, Val Accuracy: 76.19%\n",
      "Iter [51/100] - Elapsed Time: 523241.73s - Remaining Time: [512982.09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:58,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:25<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 51: Train Loss: 0.4359, Val Loss: 1.0827\n",
      "Step 51: Train Accuracy: 79.37%, Val Accuracy: 76.67%\n",
      "Iter [52/100] - Elapsed Time: 533477.03s - Remaining Time: [502699.51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:16,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:35<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 52: Train Loss: 0.4459, Val Loss: 1.3612\n",
      "Step 52: Train Accuracy: 78.53%, Val Accuracy: 76.19%\n",
      "Iter [53/100] - Elapsed Time: 543658.85s - Remaining Time: [492370.28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:44,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:32<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 53: Train Loss: 0.4342, Val Loss: 1.0435\n",
      "Step 53: Train Accuracy: 79.69%, Val Accuracy: 77.23%\n",
      "Iter [54/100] - Elapsed Time: 553879.06s - Remaining Time: [482079.92]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:30:24,  1.19it/s]\n",
      "100%|██████████| 1348/1348 [19:40<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 54: Train Loss: 0.4230, Val Loss: 1.4973\n",
      "Step 54: Train Accuracy: 79.56%, Val Accuracy: 76.91%\n",
      "Iter [55/100] - Elapsed Time: 564076.40s - Remaining Time: [471772.98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10773it [2:31:55,  1.18it/s]\n",
      "100%|██████████| 1348/1348 [19:43<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 55: Train Loss: 0.4244, Val Loss: 1.1493\n",
      "Step 55: Train Accuracy: 80.24%, Val Accuracy: 75.78%\n",
      "Iter [56/100] - Elapsed Time: 574372.90s - Remaining Time: [461549.66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4282it [1:00:31,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interrupt,\n",
      "Final Train Loss: 0.4244\n",
      "Final Val Loss: 1.1493\n",
      "Final Train Accuracy: 80.24%\n",
      "Final Val Accuracy: 75.78%\n",
      "Model and statistics saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''trying with binary cross entropy loss'''\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "from psutil import cpu_count\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dataloader import PicklebotDataset, custom_collate\n",
    "from mobilenet import MobileNetLarge2D, MobileNetSmall2D, MobileNetSmall3D,MobileNetLarge3D\n",
    "from movinet import MoViNetA2\n",
    "from helpers import calculate_accuracy_bce, average_for_plotting\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#hyperparameters\n",
    "torch.manual_seed(1234)\n",
    "learning_rate = 0.000238167787843871 #this seems nuts, but it's the lr we left off at\n",
    "batch_size = 4\n",
    "max_iters = 100\n",
    "eval_interval = 1\n",
    "weight_decay = 5e-4\n",
    "std = (0.2104, 0.1986, 0.1829)\n",
    "mean = (0.3939, 0.3817, 0.3314)\n",
    "use_autocast = False \n",
    "compile = False\n",
    "\n",
    "#video paths\n",
    "train_video_paths = '/workspace/picklebotdataset/train'\n",
    "val_video_paths = '/workspace/picklebotdataset/val'\n",
    "\n",
    "train_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/train_all_together'\n",
    "val_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/val_all_together'\n",
    "\n",
    "#annotations paths\n",
    "train_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/train_labels.csv'\n",
    "val_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/val_labels.csv'\n",
    "\n",
    "#establish normalization using transforms\n",
    "transform = transforms.Normalize(mean,std)\n",
    "\n",
    "#dataset     \n",
    "train_dataset = PicklebotDataset(train_annotations_file,train_video_paths,transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "val_dataset = PicklebotDataset(val_annotations_file,val_video_paths,transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "\n",
    "#define model\n",
    "model = MobileNetSmall3D(num_classes=1)\n",
    "model = model.to(device)\n",
    "\n",
    "#for multi-gpu\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.AdamW(params=model.parameters(),lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "#cosine annealing\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=70)\n",
    "\n",
    "#loss\n",
    "criterion = nn.BCELoss()  # Update to use Binary Cross Entropy Loss\n",
    "if use_autocast:\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "model_name = model.__class__.__name__+'bce'\n",
    "writer = SummaryWriter(f'runs/{model_name}') #tensorboard writer\n",
    "# checkpoint = torch.load(f'checkpoints/{model_name}30.pth')\n",
    "# model.load_state_dict(checkpoint)\n",
    "\n",
    "if compile:\n",
    "    print(\"compiling the model... (takes a ~minute)\")\n",
    "    model = torch.compile(model)\n",
    "    print(\"compilation complete!\")\n",
    "\n",
    "#estimate loss using the val set, and calculate accuracy\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_correct = 0\n",
    "    val_samples = 0\n",
    "\n",
    "    for val_features, val_labels in tqdm(val_loader):\n",
    "        val_features = val_features.to(device)\n",
    "        val_labels = val_labels.float().to(device)  # Convert labels to float and move to device\n",
    "        val_labels = val_labels.unsqueeze(1)  # Add a dimension to labels to match output shape\n",
    "        val_outputs = model(val_features)\n",
    "        val_outputs = torch.sigmoid(val_outputs)  # Apply sigmoid activation function\n",
    "        val_loss = criterion(val_outputs, val_labels)\n",
    "        val_losses.append(val_loss.item())\n",
    "\n",
    "        val_correct += calculate_accuracy_bce(val_outputs, val_labels)\n",
    "        val_samples += len(val_labels)\n",
    "\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    val_accuracy = val_correct / val_samples\n",
    "    return avg_val_loss, val_accuracy\n",
    "\n",
    "#training loop\n",
    "start_time = time.time()\n",
    "train_losses = torch.tensor([])\n",
    "train_percent = torch.tensor([])\n",
    "val_losses = []\n",
    "val_percent = []\n",
    "counter = 30\n",
    "\n",
    "try:\n",
    "    for iter in range(max_iters):\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_samples = 0\n",
    "        batch_loss_list = []\n",
    "        batch_percent_list = []\n",
    "\n",
    "        for batch_idx, (features, labels) in tqdm(enumerate(train_loader)):\n",
    "            labels = labels.float().to(device)  # Convert labels to float and move to device\n",
    "            labels = labels.unsqueeze(1)  # Add a dimension to labels to match output shape\n",
    "            features = features.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            if use_autocast:\n",
    "                with autocast():\n",
    "                    outputs = model(features)\n",
    "                    outputs = torch.sigmoid(outputs)  # Apply sigmoid activation function\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backprop & update weights\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(features)\n",
    "                outputs = torch.sigmoid(outputs)  # Apply sigmoid activation function\n",
    "                loss = criterion(outputs.cpu(), labels.cpu())\n",
    "\n",
    "                # Backprop & update weights\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            batch_loss_list.append(loss.item())\n",
    "            batch_correct = calculate_accuracy_bce(outputs, labels)\n",
    "            train_correct += batch_correct\n",
    "            train_samples += len(labels)\n",
    "            batch_percent_list.append(batch_correct / float(len(labels)))\n",
    "            writer.add_scalar('training loss', batch_loss_list[-1], counter)\n",
    "            writer.add_scalar('training accuracy', batch_percent_list[-1], counter)\n",
    "            counter += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        train_losses = torch.cat((train_losses, average_for_plotting(batch_loss_list)))\n",
    "        train_percent = torch.cat((train_percent, average_for_plotting(batch_percent_list)))\n",
    "        elapsed = time.time() - start_time\n",
    "        remaining_iters = max_iters - iter\n",
    "        avg_time_per_iter = elapsed / (iter + 1)\n",
    "        estimated_remaining_time = remaining_iters * avg_time_per_iter\n",
    "\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "            val_loss, val_accuracy = estimate_loss()\n",
    "            val_losses.append(val_loss)\n",
    "            val_percent.append(val_accuracy)\n",
    "\n",
    "            print(f\"Step {iter}: Train Loss: {train_losses[-1].mean().item():.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "            print(f\"Step {iter}: Train Accuracy: {(train_percent[-1].mean().item())*100:.2f}%, Val Accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "            writer.add_scalar('val loss', val_losses[-1], iter+31)\n",
    "            writer.add_scalar('val accuracy', val_percent[-1], iter+31)\n",
    "            torch.save(model.state_dict(), f'checkpoints/{model_name}{iter+31}.pth')\n",
    "\n",
    "        tqdm.write(f\"Iter [{iter+1}/{max_iters}] - Elapsed Time: {elapsed:.2f}s - Remaining Time: [{estimated_remaining_time:.2f}]\")\n",
    "\n",
    "        if iter == max_iters - 1:\n",
    "            print(\"Training completed:\")\n",
    "            print(f\"Final Train Loss: {train_losses[-1].mean().item():.4f}\")\n",
    "            print(f\"Final Val Loss: {val_losses[-1]:.4f}\")\n",
    "            print(f\"Final Train Accuracy: {(train_percent[-1].mean().item())*100:.2f}%\")\n",
    "            print(f\"Final Val Accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"Keyboard interrupt,\\nFinal Train Loss: {train_losses[-1].mean().item():.4f}\")\n",
    "    print(f\"Final Val Loss: {val_losses[-1]:.4f}\")\n",
    "    print(f\"Final Train Accuracy: {(train_percent[-1].mean().item())*100:.2f}%\")\n",
    "    print(f\"Final Val Accuracy: {val_percent[-1]*100:.2f}%\")\n",
    "finally:\n",
    "    torch.save(model.state_dict(), f'checkpoints/{model_name}_finished.pth')\n",
    "    with open(f'statistics/{model_name}_finished_train_losses.npy', 'wb') as f:\n",
    "        np.save(f, train_losses.numpy())\n",
    "    with open(f'statistics/{model_name}_finished_val_losses.npy', 'wb') as f:\n",
    "        np.save(f, np.array(val_losses))\n",
    "    with open(f'statistics/{model_name}_finished_train_percent.npy', 'wb') as f:\n",
    "        np.save(f, train_percent.numpy())\n",
    "    with open(f'statistics/{model_name}_finished_val_percent.npy', 'wb') as f:\n",
    "        np.save(f, np.array(val_percent))\n",
    "    print(f\"Model and statistics saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For testing our network'''\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from psutil import cpu_count\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader import PicklebotDataset, custom_collate\n",
    "from mobilenet import MobileNetLarge2D, MobileNetSmall2D, MobileNetSmall3D,MobileNetLarge3D\n",
    "from movinet import MoViNetA2\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "def calculate_accuracy_bce(outputs, labels, threshold=0.5):\n",
    "    # Apply threshold to obtain predicted classes and move to CPU\n",
    "    preds = (outputs >= threshold).float().cpu()\n",
    "\n",
    "    # Move labels to CPU\n",
    "    labels = labels.cpu()\n",
    "    \n",
    "    balls_correct = ((preds == 0) & (labels == 0)).sum().item() \n",
    "    strikes_correct = ((preds == 1) & (labels == 1)).sum().item() \n",
    "\n",
    "    return balls_correct, strikes_correct\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    #evaluate the model\n",
    "    model.eval()\n",
    "    test_losses = [] \n",
    "    balls_correct = 0\n",
    "    strikes_correct = 0\n",
    "    test_samples = 0\n",
    "\n",
    "    #calculate the loss\n",
    "    for test_features,test_labels in tqdm(test_loader):\n",
    "        test_features = test_features.to(device)\n",
    "        test_labels = test_labels.float().to(device) #waiting to move to device until after forward pass, idk if this matters\n",
    "        # val_labels = val_labels.expand(val_features.shape[2]) #this is only for our lstm T -> batch size, a lame hack    \n",
    "        test_outputs = model(test_features)\n",
    "        test_labels = test_labels.unsqueeze(1)\n",
    "        test_loss = criterion(test_outputs,test_labels)\n",
    "        test_losses.append(test_loss.item())\n",
    "        \n",
    "        correct_tuple = calculate_accuracy_bce(test_outputs,test_labels)\n",
    "        balls_correct += correct_tuple[0]\n",
    "        strikes_correct += correct_tuple[1]\n",
    "        test_samples += len(test_labels)\n",
    "\n",
    "    avg_test_loss = np.mean(test_losses)\n",
    "    balls_accuracy = balls_correct / 2694 #too lazy to not use the magic number from the spreadsheet rn\n",
    "    strikes_accuracy = strikes_correct / 2693 #too lazy to not use the magic number from the spreadsheet rn\n",
    "    return avg_test_loss, balls_accuracy, strikes_accuracy \n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "std = (0.2104, 0.1986, 0.1829)\n",
    "mean = (0.3939, 0.3817, 0.3314)\n",
    "batch_size = 4 \n",
    "\n",
    "#annotations paths\n",
    "test_annotations_file = '/home/henry/Documents/PythonProjects/picklebotdataset/test_labels.csv'\n",
    "\n",
    "#video paths\n",
    "test_video_paths = '/home/henry/Documents/PythonProjects/picklebotdataset/test_all_together'\n",
    "\n",
    "#establish our normalization using transforms, \n",
    "#note that we are doing this in our dataloader as opposed to in the training loop like with dali\n",
    "transform = transforms.Normalize(mean,std)\n",
    "\n",
    "#dataset     \n",
    "test_dataset = PicklebotDataset(test_annotations_file,test_video_paths,transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,shuffle=True,collate_fn=custom_collate,num_workers=cpu_count())\n",
    "\n",
    "model = MobileNetSmall3D(num_classes=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "for i in range(25,50):\n",
    "    model.load_state_dict(torch.load(f'checkpoints/MobileNetSmall3Dbce{i}.pth'))\n",
    "    model.to(device)\n",
    "    avg_test_loss,balls_accuracy,strikes_accuracy = estimate_loss()\n",
    "\n",
    "    print(f'mobilenet small {i} test loss: {avg_test_loss:.4f}, mobilenet small ball test accuracy: {balls_accuracy * 100:.2f}% mobilenet small strike test accuracy: {strikes_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters in movinet: 4660762\n",
      "number of parameters in mobilenet large: 4191584\n",
      "number of parameters in mobilenet small: 1672816\n"
     ]
    }
   ],
   "source": [
    "'''Calculate the number of parameters in each model, for comparison purposes. \n",
    "   Note that movinet is about 2.8x larger than mobilenet small, and mobilenet large is about 2.5x larger than mobilenet small.'''\n",
    "\n",
    "from movinet import MoViNetA2\n",
    "from mobilenet import MobileNetLarge3D\n",
    "movinet = MoViNetA2()\n",
    "mobilenet_large = MobileNetLarge3D()\n",
    "mobilenet_small = MobileNetSmall3D()\n",
    "\n",
    "movinet_params = sum(p.numel() for p in movinet.parameters())\n",
    "mobilenet_large_params = sum(p.numel() for p in mobilenet_large.parameters())\n",
    "mobilenet_small_params = sum(p.numel() for p in mobilenet_small.parameters())\n",
    "print(f\"number of parameters in movinet: {movinet_params}\")\n",
    "print(f\"number of parameters in mobilenet large: {mobilenet_large_params}\")\n",
    "print(f\"number of parameters in mobilenet small: {mobilenet_small_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
